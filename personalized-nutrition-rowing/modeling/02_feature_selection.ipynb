{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550eccd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from pathlib import Path \n",
    "CURRENT_DIR = Path.cwd()\n",
    "PROJECT_ROOT = CURRENT_DIR.parent\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"output\"\n",
    "\n",
    "def eda_correlation_analysis(data_path, output_plot_path, target_column_name=\"Rowing distance\", correlation_threshold=0.8): # 默认目标列名改为小写d\n",
    "    \"\"\"\n",
    "    Performs correlation analysis on input features.\n",
    "\n",
    "    Args:\n",
    "        data_path (str): Path to the Excel data file.\n",
    "        output_plot_path (str): Directory to save the output plots.\n",
    "        target_column_name (str): Name of the target variable column.\n",
    "        correlation_threshold (float): Absolute correlation value above which pairs are considered highly correlated.\n",
    "    \"\"\"\n",
    "    # --- 1. 数据加载和准备 ---\n",
    "    try:\n",
    "        print(f\"正在加载数据从: {data_path}\")\n",
    "        df = pd.read_excel(data_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 文件未找到 {data_path}\")\n",
    "        return None, None # 返回 None 表示失败\n",
    "    except Exception as e:\n",
    "        print(f\"加载数据时发生错误: {e}\")\n",
    "        return None, None # 返回 None 表示失败\n",
    "\n",
    "    print(\"数据加载成功。数据前5行:\")\n",
    "    print(df.head())\n",
    "    print(f\"\\n数据形状: {df.shape}\")\n",
    "\n",
    "    # 确保目标列存在\n",
    "    if target_column_name not in df.columns:\n",
    "        actual_last_col_name = df.columns[-1]\n",
    "        print(f\"警告: 指定的目标列名 '{target_column_name}' 未在数据列中找到。\")\n",
    "        if target_column_name.lower() == actual_last_col_name.lower():\n",
    "             print(f\"检测到大小写不匹配，将使用实际列名 '{actual_last_col_name}' 作为目标。\")\n",
    "             target_column_name = actual_last_col_name\n",
    "        else:\n",
    "            print(f\"将尝试使用最后一列 '{actual_last_col_name}' 作为目标列。请确认这是否正确。\")\n",
    "            target_column_name = actual_last_col_name\n",
    "    \n",
    "    if target_column_name not in df.columns: # 再次检查，如果最后一列也不是，则严重错误\n",
    "        print(f\"错误: 无法确定目标列。提供的 '{target_column_name}' 和最后一列都不是有效的列名。\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "    X = df.drop(columns=[target_column_name])\n",
    "    # y = df[target_column_name] # 目标变量，当前分析中未使用，但已分离\n",
    "\n",
    "    print(f\"\\n输入特征数量: {X.shape[1]}\")\n",
    "    print(f\"识别出的目标变量: {target_column_name}\")\n",
    "\n",
    "    # --- 2. 计算输入特征之间的相关系数矩阵 ---\n",
    "    print(\"\\n正在计算相关系数矩阵 (仅针对输入特征)...\")\n",
    "    corr_matrix = X.corr()\n",
    "\n",
    "    # --- 3. 可视化相关系数矩阵 (热力图) ---\n",
    "    print(\"正在生成热力图...\")\n",
    "    try:\n",
    "        # 尝试使用一个更兼容的seaborn样式，如果仍然报错，可以注释掉下面这行\n",
    "        plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    except OSError:\n",
    "        print(\"警告: 无法加载 'seaborn-v0_8-whitegrid' 样式。将使用matplotlib默认样式。\")\n",
    "        # 如果需要，可以在这里设置一些基本的rcParams来美化，例如：\n",
    "        # plt.rcParams['figure.facecolor'] = 'white'\n",
    "        # plt.rcParams['axes.edgecolor'] = '.8'\n",
    "        # plt.rcParams['grid.color'] = '.9'\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(max(15, X.shape[1]*0.45), max(15, X.shape[1]*0.4))) # 略微调整了大小计算\n",
    "\n",
    "    # 使用发散型色板，类似于医学期刊风格 (例如，红-白-蓝)\n",
    "    cmap = sns.diverging_palette(250, 15, s=80, l=55, n=9, center=\"light\", as_cmap=True) # 调整了饱和度和亮度\n",
    "\n",
    "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "\n",
    "    sns.heatmap(corr_matrix,\n",
    "                mask=mask,\n",
    "                cmap=cmap,\n",
    "                vmin=-1, vmax=1, center=0,\n",
    "                square=True,\n",
    "                linewidths=.3, # 减小线宽\n",
    "                cbar_kws={\"shrink\": .75, \"label\": \"Correlation Coefficient\", \"aspect\": 30}, # 调整颜色条长宽比\n",
    "                annot=False,\n",
    "                fmt=\".2f\")\n",
    "\n",
    "    plt.title(f'Correlation Matrix of Input Features ({X.shape[1]} features)', fontsize=18, pad=20) # 增加标题字体和间距\n",
    "    # plt.xticks(rotation=90, ha='right', fontsize=9) # 增加X轴标签字体\n",
    "    # plt.yticks(rotation=0, fontsize=9) # 增加Y轴标签字体\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=16)   # 横坐标倾斜 45°\n",
    "    plt.yticks(rotation=0, ha='right', fontsize=16)   # 纵坐标倾斜 45°\n",
    "    plt.tight_layout(pad=1.5) # 调整整体布局，增加边距\n",
    "\n",
    "    os.makedirs(output_plot_path, exist_ok=True)\n",
    "    heatmap_filename = os.path.join(output_plot_path, \"input_features_correlation_heatmap.png\")\n",
    "\n",
    "    try:\n",
    "        plt.savefig(heatmap_filename, dpi=300, bbox_inches='tight')\n",
    "        print(f\"\\n热力图已保存至: {heatmap_filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"保存热力图时发生错误: {e}\")\n",
    "    plt.show()\n",
    "\n",
    "    # --- 4. 识别并输出高度相关的特征对 ---\n",
    "    print(f\"\\n寻找绝对相关系数 > {correlation_threshold} 的特征对:\")\n",
    "    highly_correlated_pairs = []\n",
    "    upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "    for column in upper_tri.columns:\n",
    "        for index in upper_tri.index:\n",
    "            correlation_value = upper_tri.loc[index, column]\n",
    "            if pd.notna(correlation_value) and abs(correlation_value) > correlation_threshold:\n",
    "                highly_correlated_pairs.append(((index, column), correlation_value))\n",
    "\n",
    "    if highly_correlated_pairs:\n",
    "        print(f\"共找到 {len(highly_correlated_pairs)} 对高度相关的特征:\")\n",
    "        highly_correlated_pairs.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "        for pair_info in highly_correlated_pairs:\n",
    "            features, value = pair_info\n",
    "            print(f\"  特征对: {features[0]} 和 {features[1]}, 相关系数: {value:.3f}\")\n",
    "    else:\n",
    "        print(f\"未找到绝对相关系数高于 {correlation_threshold} 的强相关特征对。\")\n",
    "\n",
    "    print(\"\\nEDA相关性分析完成。\")\n",
    "    return corr_matrix, highly_correlated_pairs\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # --- 用户配置 ---\n",
    "    data_file_path = DATA_DIR / \"development_set.xlsx\"\n",
    "    plots_output_directory = OUTPUT_DIR\n",
    "    \n",
    "    # !!! 重要: 请根据你的Excel文件，确认最后一列目标变量的准确列名(区分大小写) !!!\n",
    "    # 根据你的错误日志，实际列名似乎是 'Rowing distance' (小写d)\n",
    "    target_col = \"Rowing distance\" \n",
    "    \n",
    "    correlation_abs_threshold = 0.8\n",
    "\n",
    "    # --- 执行分析 ---\n",
    "    correlation_matrix, correlated_pairs = eda_correlation_analysis(\n",
    "        data_path=data_file_path,\n",
    "        output_plot_path=plots_output_directory,\n",
    "        target_column_name=target_col,\n",
    "        correlation_threshold=correlation_abs_threshold\n",
    "    )\n",
    "    \n",
    "    if correlated_pairs is not None: # 检查是否成功执行\n",
    "        try:\n",
    "            correlated_pairs_df = pd.DataFrame(\n",
    "                [(p[0][0], p[0][1], p[1]) for p in correlated_pairs],\n",
    "                columns=['Feature 1', 'Feature 2', 'Correlation Coefficient']\n",
    "            )\n",
    "            correlated_pairs_filename = os.path.join(plots_output_directory, \"highly_correlated_feature_pairs.csv\")\n",
    "            correlated_pairs_df.to_csv(correlated_pairs_filename, index=False)\n",
    "            print(f\"\\n高度相关的特征对列表已保存至: {correlated_pairs_filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"保存高度相关特征对列表时发生错误: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed2aa5e-a2c1-4588-ae77-c1d51d0bc868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于原始数据 - 46\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import KFold, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import os # 导入os模块用于创建文件夹\n",
    "\n",
    "from pathlib import Path \n",
    "CURRENT_DIR = Path.cwd()\n",
    "PROJECT_ROOT = CURRENT_DIR.parent\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"output\"\n",
    "\n",
    "import xgboost as xgb\n",
    "try:\n",
    "    print(\"尝试使用GPU初始化一个简单的XGBoost模型...\")\n",
    "    # 尝试初始化一个使用gpu_hist的模型\n",
    "    # 如果这一步没有因为GPU问题报错，说明XGBoost至少能识别并尝试使用GPU\n",
    "    temp_model = xgb.XGBClassifier(tree_method='gpu_hist')\n",
    "    # 或者对于回归任务\n",
    "    # temp_model = xgb.XGBRegressor(tree_method='gpu_hist')\n",
    "    print(\"XGBoost GPU tree_method ('gpu_hist') 初始化成功。\")\n",
    "    # 你甚至可以尝试一个非常小的数据集进行拟合来确认\n",
    "    # import numpy as np\n",
    "    # temp_model.fit(np.array([[1],[2]]), np.array([0,1]))\n",
    "    # print(\"简单模型在GPU上拟合成功。\")\n",
    "except xgb.core.XGBoostError as e:\n",
    "    print(f\"XGBoost GPU 初始化或测试失败: {e}\")\n",
    "    print(\"请检查：\")\n",
    "    print(\"1. XGBoost是否安装了GPU版本 (例如，通过 'conda install py-xgboost-gpu' 或确保pip安装的是GPU编译版)。\")\n",
    "    print(\"2. NVIDIA驱动程序是否已正确安装且为最新。\")\n",
    "    print(\"3. NVIDIA CUDA Toolkit是否已正确安装并与驱动程序/XGBoost版本兼容。\")\n",
    "    print(\"4. CUDA相关的环境变量路径是否设置正确。\")\n",
    "except Exception as e:\n",
    "    print(f\"发生其他错误在尝试GPU初始化时: {e}\")\n",
    "# --- 配置部分 ---\n",
    "# !!! 注意: 请确保将此路径更改为你的实际文件路径 !!!\n",
    "data_path = DATA_DIR / \"development_set.xlsx\" \n",
    "# !!! 注意: 请确保 'target' 是你数据中实际的目标变量列名 !!!\n",
    "target_column_name = 'Rowing distance' # 如果你的目标列名不同 (例如 'Rowing_Distance'), 请相应修改\n",
    "\n",
    "# 图表导出路径\n",
    "output_plot_path = OUTPUT_DIR\n",
    "# 创建导出路径 (如果不存在)\n",
    "os.makedirs(output_plot_path, exist_ok=True)\n",
    "\n",
    "\n",
    "# --- 数据加载 ---\n",
    "original_data = pd.read_excel(data_path)\n",
    "X_original = original_data.drop(columns=[target_column_name])\n",
    "y_original = original_data[target_column_name]\n",
    "\n",
    "# --- XGBoost 超参数调优 ---\n",
    "# 准备 RandomizedSearchCV 的参数网格\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],\n",
    "    'subsample': [0.7, 0.8, 0.9, 1],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9, 1],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3],\n",
    "    'reg_alpha': [0, 0.01, 0.1, 0.5, 1],\n",
    "    'reg_lambda': [0.5, 1, 1.5, 2]\n",
    "}\n",
    "\n",
    "# 初始化 XGBoost 回归器模型\n",
    "# 修改: 添加 tree_method='gpu_hist' 以尝试使用GPU; objective='reg:squarederror' 是常见的回归目标函数\n",
    "# 注意: GPU加速需要兼容的硬件和软件环境\n",
    "xgb_regressor_base = XGBRegressor(objective='reg:squarederror', tree_method='gpu_hist', random_state=42)\n",
    "\n",
    "print(\"开始超参数调优 (RandomizedSearchCV)...\")\n",
    "# 在原始数据集上执行 Randomized Search (5折交叉验证) 寻找最佳参数\n",
    "random_search_original = RandomizedSearchCV(\n",
    "    estimator=xgb_regressor_base,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=50,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=1 # 使用所有可用CPU核心进行交叉验证的并行处理\n",
    ")\n",
    "random_search_original.fit(X_original, y_original)\n",
    "\n",
    "best_params_original = random_search_original.best_params_\n",
    "print(\"最佳参数 (原始数据):\", best_params_original)\n",
    "print(f\"最佳交叉验证得分 ({random_search_original.scoring}): {random_search_original.best_score_}\")\n",
    "\n",
    "\n",
    "# --- K折交叉验证评估 ---\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results_original_metrics = []\n",
    "train_losses = [] # 每折的训练损失 (MAE)\n",
    "test_losses = []  # 每折的测试损失 (MAE)\n",
    "\n",
    "print(\"\\n使用最佳参数进行K折交叉验证评估:\")\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_original), 1):\n",
    "    X_train, X_test = X_original.iloc[train_index], X_original.iloc[test_index]\n",
    "    y_train, y_test = y_original.iloc[train_index], y_original.iloc[test_index]\n",
    "\n",
    "    # 使用最佳参数初始化 XGBoost 回归器模型\n",
    "    # 修改: 添加 tree_method='gpu_hist'\n",
    "    xgb_regressor_fold = XGBRegressor(**best_params_original, objective='reg:squarederror', tree_method='gpu_hist', random_state=42)\n",
    "\n",
    "    eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "    xgb_regressor_fold.fit(X_train, y_train, eval_metric='mae', eval_set=eval_set, early_stopping_rounds=10, verbose=False)\n",
    "\n",
    "    fold_results_eval = xgb_regressor_fold.evals_result()\n",
    "    train_losses.append(fold_results_eval['validation_0']['mae'])\n",
    "    test_losses.append(fold_results_eval['validation_1']['mae'])\n",
    "\n",
    "    y_pred_test = xgb_regressor_fold.predict(X_test)\n",
    "    y_pred_train = xgb_regressor_fold.predict(X_train)\n",
    "\n",
    "    mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "    mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "    rmse_test = np.sqrt(mse_test)\n",
    "    r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "    mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "    rmse_train = np.sqrt(mse_train)\n",
    "    r2_train = r2_score(y_train, y_pred_train)\n",
    "\n",
    "    print(f\"Fold {fold} Results: Train MAE: {mae_train:.4f}, Train R2: {r2_train:.4f} | Test MAE: {mae_test:.4f}, Test R2: {r2_test:.4f}\")\n",
    "    results_original_metrics.append((mae_test, mse_test, rmse_test, r2_test, mae_train, mse_train, rmse_train, r2_train))\n",
    "\n",
    "# --- 计算平均性能 ---\n",
    "avg_mae_test = np.mean([res[0] for res in results_original_metrics])\n",
    "avg_mse_test = np.mean([res[1] for res in results_original_metrics])\n",
    "avg_rmse_test = np.mean([res[2] for res in results_original_metrics])\n",
    "avg_r2_test = np.mean([res[3] for res in results_original_metrics])\n",
    "\n",
    "avg_mae_train = np.mean([res[4] for res in results_original_metrics])\n",
    "avg_mse_train = np.mean([res[5] for res in results_original_metrics])\n",
    "avg_rmse_train = np.mean([res[6] for res in results_original_metrics])\n",
    "avg_r2_train = np.mean([res[7] for res in results_original_metrics])\n",
    "\n",
    "print(\"\\nOriginal Data - Average Test Performance:\")\n",
    "print(f\"  MAE: {avg_mae_test:.4f}\")\n",
    "print(f\"  MSE: {avg_mse_test:.4f}\")\n",
    "print(f\"  RMSE: {avg_rmse_test:.4f}\")\n",
    "print(f\"  R2 Score: {avg_r2_test:.4f}\")\n",
    "\n",
    "print(\"\\nOriginal Data - Average Train Performance:\")\n",
    "print(f\"  MAE: {avg_mae_train:.4f}\")\n",
    "print(f\"  MSE: {avg_mse_train:.4f}\")\n",
    "print(f\"  RMSE: {avg_rmse_train:.4f}\")\n",
    "print(f\"  R2 Score: {avg_r2_train:.4f}\")\n",
    "\n",
    "# --- 绘制图表并导出 ---\n",
    "\n",
    "# 绘制评估指标图 (MAE 和 R2)\n",
    "metrics_plot_names_en = ['MAE', 'R2 Score'] # 英文指标名称\n",
    "values_test_plot = [avg_mae_test, avg_r2_test]\n",
    "values_train_plot = [avg_mae_train, avg_r2_train]\n",
    "\n",
    "x_axis_plot = np.arange(len(metrics_plot_names_en))\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(x_axis_plot - 0.2, values_train_plot, width=0.4, label='Train', align='center')\n",
    "plt.bar(x_axis_plot + 0.2, values_test_plot, width=0.4, label='Test', align='center')\n",
    "plt.xticks(x_axis_plot, metrics_plot_names_en)\n",
    "plt.ylabel('Score') # Y轴标签改为英文\n",
    "plt.title('Average Train vs. Test Set Evaluation Metrics (Original Data)') # 标题改为英文\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "# 导出图表\n",
    "plot_filename_metrics = os.path.join(output_plot_path, \"average_evaluation_metrics.png\")\n",
    "plt.savefig(plot_filename_metrics, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 绘制每折的训练和测试损失 (MAE)\n",
    "plt.figure(figsize=(14, 7))\n",
    "for i in range(len(train_losses)):\n",
    "    plt.plot(train_losses[i], label=f'Train Fold {i+1}', linestyle='-')\n",
    "    plt.plot(test_losses[i], label=f'Test Fold {i+1}', linestyle='--')\n",
    "plt.xlabel('Boosting Round') # X轴标签改为英文\n",
    "plt.ylabel('Mean Absolute Error (MAE)') # Y轴标签改为英文\n",
    "plt.title('Training and Testing MAE per Fold (Original Data)') # 标题改为英文\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "# 导出图表\n",
    "plot_filename_loss = os.path.join(output_plot_path, \"mae_loss_per_fold.png\")\n",
    "plt.savefig(plot_filename_loss, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- 过拟合检查 ---\n",
    "r2_diff = avg_r2_train - avg_r2_test\n",
    "print(\"\\nOverfitting Check:\")\n",
    "# 这里的过拟合判断逻辑可以根据具体需求调整\n",
    "if r2_diff > 0.1 and avg_r2_train > avg_r2_test: # 训练R2显著高于测试R2\n",
    "    print(f\"Warning: Model might be overfitting! Train R2 ({avg_r2_train:.2f}) is significantly higher than Test R2 ({avg_r2_test:.2f}). Difference: {r2_diff:.2f}\")\n",
    "elif avg_mae_test > 0 and avg_mae_train > 0 and (avg_mae_test - avg_mae_train) / avg_mae_train > 0.20 : # 测试MAE比训练MAE高出20%\n",
    "     print(f\"Warning: Model might be overfitting! Test MAE ({avg_mae_test:.2f}) is >20% higher than Train MAE ({avg_mae_train:.2f}). Relative difference: {((avg_mae_test - avg_mae_train) / avg_mae_train)*100:.2f}%.\")\n",
    "else:\n",
    "    print(f\"No strong signs of overfitting detected based on current thresholds. R2 Diff (Train-Test): {r2_diff:.2f}. MAE Train: {avg_mae_train:.2f}, MAE Test: {avg_mae_test:.2f}.\")\n",
    "\n",
    "\n",
    "# --- 特征重要性分析 ---\n",
    "print(\"\\nFeature Importance Analysis:\")\n",
    "# 修改: 添加 tree_method='gpu_hist'\n",
    "final_model = XGBRegressor(**best_params_original, objective='reg:squarederror', tree_method='gpu_hist', random_state=42)\n",
    "final_model.fit(X_original, y_original)\n",
    "\n",
    "feature_importances = final_model.feature_importances_\n",
    "importance_df = pd.DataFrame({'Feature': X_original.columns, 'Importance': feature_importances})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importances (High to Low):\")\n",
    "print(importance_df.head(min(20, len(X_original.columns)))) # 打印最重要的，最多20个\n",
    "\n",
    "# 绘制特征重要性图\n",
    "# 动态调整图像高度以容纳特征名称\n",
    "num_features_to_plot = min(20, len(X_original.columns))\n",
    "plot_height = max(6, num_features_to_plot * 0.4) # 根据特征数量调整高度\n",
    "plt.figure(figsize=(10, plot_height))\n",
    "plt.barh(importance_df['Feature'][:num_features_to_plot], importance_df['Importance'][:num_features_to_plot])\n",
    "plt.xlabel('Feature Importance') # X轴标签改为英文\n",
    "plt.ylabel('Feature') # Y轴标签改为英文\n",
    "plt.title(f'Top {num_features_to_plot} Feature Importances') # 标题改为英文\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.grid(True, axis='x', linestyle='--', alpha=0.7) # 只显示X轴网格线\n",
    "# 导出图表\n",
    "plot_filename_importance = os.path.join(output_plot_path, \"feature_importances原始.png\")\n",
    "plt.savefig(plot_filename_importance, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n所有图表已尝试保存至: {output_plot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003b1e66-a53b-44ae-aed9-e892653a86c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试集多余指标剔除\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from pathlib import Path \n",
    "CURRENT_DIR = Path.cwd()\n",
    "PROJECT_ROOT = CURRENT_DIR.parent\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"output\"\n",
    "\n",
    "# --- 用户配置 ---\n",
    "# 输入文件路径和名称\n",
    "input_folder_path = DATA_DIR\n",
    "input_file_name = \"final_test_set.xlsx\"\n",
    "full_input_path = DATA_DIR/ input_file_name\n",
    "\n",
    "# 输出文件名\n",
    "output_file_name = \"final_test_set_selected_features.xlsx\" # Changed output name slightly for clarity\n",
    "full_output_path = DATA_DIR / output_file_name\n",
    "\n",
    "# 需要保留的22个指标的准确名称列表 (21输入特征 + 1目标变量)\n",
    "# !!! 请务必确保以下列表中的名称与你 \"data.xlsx\" 文件中第一行的标题完全一致 (包括大小写和空格) !!!\n",
    "columns_to_keep = [\n",
    "    \"PARS – 3\",  # 请注意这里的'–'是en-dash，如果Excel中是普通连字符'-', 可能需要修改\n",
    "    \"average vertical jump height before exercise\",\n",
    "    \"Alcohol use in the last 30 days\",\n",
    "    \"weight\",\n",
    "    \"CHO\",\n",
    "    \"Smoking frequency in the last 30 days\",\n",
    "    \"Triceps skinfold\",\n",
    "    \"Left-hand grip strength\",\n",
    "    \"subgluteal thigh circumference\",\n",
    "    \"hip circumference\",\n",
    "    \"Age\",\n",
    "    \"Previous meal time\",\n",
    "    \"light sleep\", # Ensure this is the exact column name in your Excel\n",
    "    \"RMSSD\", # Ensure this is the exact column name for the HRV RMSSD component in your Excel\n",
    "    \"high blood pressure\", # Ensure this is the exact column name\n",
    "    \"waist circumference\",\n",
    "    \"hemoglobin\", # Ensure this is the exact column name\n",
    "    \"Body water percentage\", # Ensure this is the exact column name\n",
    "    \"blood lactate\", # Ensure this is the exact name for baseline blood lactate\n",
    "    \"PRO\", # Kept based on domain knowledge\n",
    "    \"Blood glucose\", # Kept based on domain knowledge, ensure exact name for baseline\n",
    "    \"Rowing distance\" # 目标变量\n",
    "]\n",
    "\n",
    "# --- 执行操作 ---\n",
    "try:\n",
    "    # 1. 读取原始Excel文件\n",
    "    print(f\"正在从以下路径加载原始数据: {full_input_path}\")\n",
    "    original_df = pd.read_excel(full_input_path)\n",
    "    print(\"原始数据加载成功。\")\n",
    "    print(f\"原始数据包含 {original_df.shape[0]} 行 和 {original_df.shape[1]} 列。\")\n",
    "    print(\"原始数据列名:\", original_df.columns.tolist())\n",
    "\n",
    "    # 2. 检查需要保留的列是否存在于原始数据中\n",
    "    missing_columns = [col for col in columns_to_keep if col not in original_df.columns]\n",
    "    if missing_columns:\n",
    "        print(\"\\n警告：以下指定的列在原始文件中未找到，它们将被忽略：\")\n",
    "        for col in missing_columns:\n",
    "            print(f\" - '{col}'\")\n",
    "        # 更新 columns_to_keep 列表，只包含实际存在的列\n",
    "        columns_to_keep_actual = [col for col in columns_to_keep if col in original_df.columns]\n",
    "        if not columns_to_keep_actual:\n",
    "            print(\"错误：所有指定的保留列都不在原始文件中或指定的列均缺失。无法继续。\")\n",
    "            exit() # 或者 raise ValueError\n",
    "    else:\n",
    "        columns_to_keep_actual = columns_to_keep\n",
    "\n",
    "    # 如果之前有列缺失或为了确认，打印实际将操作的列数\n",
    "    expected_columns_count = 22\n",
    "    if len(columns_to_keep_actual) < expected_columns_count:\n",
    "        print(f\"\\n注意：预期保留 {expected_columns_count} 个指标，但由于部分指定列未找到，\")\n",
    "        print(f\"实际将仅基于以下 {len(columns_to_keep_actual)} 个在文件中找到的指定指标进行操作。\")\n",
    "    elif len(columns_to_keep_actual) > expected_columns_count:\n",
    "        print(f\"\\n注意：预期保留 {expected_columns_count} 个指标，但列表中指定了 {len(columns_to_keep_actual)} 个指标。\")\n",
    "        print(f\"将按列表中指定的 {len(columns_to_keep_actual)} 个指标进行操作。\")\n",
    "\n",
    "\n",
    "    # 3. 筛选出指定的列\n",
    "    print(f\"\\n正在筛选以下 {len(columns_to_keep_actual)} 个指标:\")\n",
    "    for col in columns_to_keep_actual:\n",
    "        print(f\" - '{col}'\")\n",
    "    \n",
    "    selected_df = original_df[columns_to_keep_actual]\n",
    "    print(\"\\n指标筛选完成。\")\n",
    "    print(f\"筛选后的数据包含 {selected_df.shape[0]} 行 和 {selected_df.shape[1]} 列。\")\n",
    "\n",
    "    # 4. 将筛选后的数据保存到新的Excel文件\n",
    "    print(f\"\\n正在将筛选后的数据保存到: {full_output_path}\")\n",
    "    selected_df.to_excel(full_output_path, index=False) # index=False 避免将pandas的索引写入Excel\n",
    "    print(f\"数据已成功保存到 {full_output_path}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"错误: 输入文件未找到 '{full_input_path}'。请检查路径和文件名。\")\n",
    "except KeyError as e:\n",
    "    # This specific KeyError for column not found during selection should be less likely\n",
    "    # now due to the pre-check, but kept as a safeguard.\n",
    "    print(f\"错误: 在筛选过程中，原始文件中找不到指定的列: {e}。\")\n",
    "    print(\"这通常发生在 'columns_to_keep_actual' 列表中的列名与Excel中的标题在筛选前检查后仍不匹配（罕见）。\")\n",
    "except Exception as e:\n",
    "    print(f\"处理过程中发生了一个意料之外的错误: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (xgb_gpu_env)",
   "language": "python",
   "name": "xgb_gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
