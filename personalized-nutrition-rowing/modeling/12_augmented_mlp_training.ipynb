{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db12543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import joblib # 虽然BPNN不用joblib存，但保留以防万一有其他用途或习惯\n",
    "\n",
    "\n",
    "from pathlib import Path \n",
    "CURRENT_DIR = Path.cwd()\n",
    "PROJECT_ROOT = CURRENT_DIR.parent\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"output\"\n",
    "\n",
    "\n",
    "\n",
    "# --- 0. 全局配置 ---\n",
    "# 数据路径\n",
    "BASE_DATA_PATH = DATA_DIR\n",
    "DEV_SET_FILE = DATA_DIR / \"development_set_selected_features.xlsx\"\n",
    "TEST_SET_FILE = DATA_DIR / \"final_test_set_selected_features.xlsx\"\n",
    "AUGMENTED_DATA_OUTPUT_FOLDER =  DATA_DIR / \"augmented_outputs_bpnn\" # BPNN的增强数据输出\n",
    "MODEL_OUTPUT_PATH =  DATA_DIR / \"trained_models_bpnn\"      # BPNN的模型保存路径\n",
    "OUTPUT_PLOT_PATH = OUTPUT_DIR # 图表导出路径\n",
    "\n",
    "os.makedirs(AUGMENTED_DATA_OUTPUT_FOLDER, exist_ok=True)\n",
    "os.makedirs(MODEL_OUTPUT_PATH, exist_ok=True)\n",
    "os.makedirs(OUTPUT_PLOT_PATH, exist_ok=True)\n",
    "\n",
    "TARGET_COLUMN = 'Rowing distance'\n",
    "RANDOM_STATE = 42\n",
    "N_SPLITS_KFOLD = 5 # K-Fold的折数\n",
    "\n",
    "# WGAN-GP 预设参数 (与XGBoost脚本一致)\n",
    "# CHO_LEVELS = np.array([0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2])\n",
    "DEFAULT_WGAN_PARAMS = {\n",
    "    'latent_dim': 100,\n",
    "    'lambda_gp': 10,\n",
    "    'n_critic': 5,\n",
    "    'lr': 0.00005, # WGAN-GP学习率\n",
    "    'batch_size': 32, # WGAN-GP的batch_size\n",
    "    'epochs_for_cv': 500, # K-Fold内部动态增强时WGAN-GP使用的轮数\n",
    "    'epochs_for_final_hpo': 2000 # 用于HPO或最终增强开发集时WGAN-GP的轮数 (原为epochs_for_final: 3000，可按需调整)\n",
    "}\n",
    "\n",
    "# BPNN 超参数搜索范围 (基于之前的讨论，考虑了正则化和适度简化)\n",
    "BPNN_PARAM_GRID = {\n",
    "    'learning_rate': [0.0005, 0.001, 0.005], # BPNN学习率\n",
    "    'hidden_dims': [\n",
    "        [64],\n",
    "        [32, 16],\n",
    "        [64, 32],\n",
    "        [128, 64] # 略微增加一点复杂度的选项，因为有数据增强\n",
    "    ],\n",
    "    'batch_size': [16, 32, 64], # BPNN的batch_size\n",
    "    'dropout_rate': [0.2, 0.3, 0.4, 0.5],\n",
    "    'weight_decay': [1e-5, 1e-4, 5e-4, 1e-3]\n",
    "}\n",
    "N_ITER_BPNN_HPO = 25 # BPNN HPO的迭代次数 (原XGB是30)\n",
    "\n",
    "# BPNN 训练时期数和耐心\n",
    "EPOCHS_BPNN_HPO = 75       # BPNN HPO时每个配置的训练轮数 (原50)\n",
    "PATIENCE_BPNN_HPO = 10      # BPNN HPO时的早停耐心 (原5)\n",
    "EPOCHS_BPNN_CV_FINAL = 250  # BPNN CV折训练和最终模型训练的轮数 (原200)\n",
    "PATIENCE_BPNN_CV_FINAL = 20 # BPNN CV折和最终模型早停耐心 (原15)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"将使用设备: {device}\")\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "set_seed(RANDOM_STATE)\n",
    "\n",
    "# --- 1. WGAN-GP 模型定义 (与XGBoost脚本一致) ---\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128), nn.ReLU(),\n",
    "            nn.Linear(128, 256), nn.ReLU(),\n",
    "            nn.Linear(256, 512), nn.ReLU(),\n",
    "            nn.Linear(512, output_dim)\n",
    "        )\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Critic, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512), nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256), nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 128), nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "def gradient_penalty(critic_model, real_samples, fake_samples, device_in_use):\n",
    "    batch_size_gp = real_samples.size(0)\n",
    "    alpha = torch.rand(batch_size_gp, 1, device=device_in_use).expand_as(real_samples)\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "    d_interpolates = critic_model(interpolates)\n",
    "    fake_grad_output = torch.ones_like(d_interpolates, device=device_in_use)\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=d_interpolates, inputs=interpolates, grad_outputs=fake_grad_output,\n",
    "        create_graph=True, retain_graph=True, only_inputs=True\n",
    "    )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty_val = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty_val\n",
    "\n",
    "# --- 2. WGAN-GP 训练与生成辅助函数 (与XGBoost脚本基本一致) ---\n",
    "def train_and_generate_wgangp(input_original_df,\n",
    "                              target_col_name,\n",
    "                              wgan_hyperparams,\n",
    "                              num_samples_to_generate,\n",
    "                              current_device,\n",
    "                              fold_num_for_logging=None,\n",
    "                              output_augmented_data_path=None):\n",
    "    log_prefix = f\"[WGAN-GP\"\n",
    "    if isinstance(fold_num_for_logging, int):\n",
    "        log_prefix += f\" Fold {fold_num_for_logging}\"\n",
    "    elif isinstance(fold_num_for_logging, str):\n",
    "        log_prefix += f\" Stage {fold_num_for_logging}\"\n",
    "    log_prefix += \"]\"\n",
    "    print(f\"\\n{log_prefix} 开始WGAN-GP处理，输入数据形状: {input_original_df.shape}\")\n",
    "\n",
    "    all_feature_names = input_original_df.columns.tolist()\n",
    "    original_data_values = input_original_df.values.astype(np.float32)\n",
    "\n",
    "    data_mean = np.mean(original_data_values, axis=0)\n",
    "    data_std = np.std(original_data_values, axis=0)\n",
    "    data_std[data_std == 0] = 1\n",
    "    standardized_data = (original_data_values - data_mean) / data_std\n",
    "\n",
    "    data_tensor = torch.tensor(standardized_data, dtype=torch.float32) # Ensure float32 for PyTorch\n",
    "    dataset = TensorDataset(data_tensor)\n",
    "    \n",
    "    current_batch_size = min(wgan_hyperparams['batch_size'], len(dataset))\n",
    "    if current_batch_size == 0:\n",
    "        print(f\"{log_prefix} 错误：WGAN-GP数据集为空或过小 ({len(dataset)} samples), 无法创建DataLoader。\")\n",
    "        return pd.DataFrame(columns=all_feature_names)\n",
    "    \n",
    "    use_drop_last = len(dataset) >= current_batch_size * 2\n",
    "    dataloader = DataLoader(dataset, batch_size=current_batch_size, shuffle=True, drop_last=use_drop_last)\n",
    "    \n",
    "    if len(dataloader) == 0 and len(dataset) > 0 :\n",
    "        dataloader = DataLoader(dataset, batch_size=current_batch_size, shuffle=True, drop_last=False)\n",
    "        if len(dataloader) == 0 and len(dataset) > 0:\n",
    "             print(f\"{log_prefix} 错误: WGAN-GP DataLoader仍然为空。无法继续GAN训练。\")\n",
    "             return pd.DataFrame(columns=all_feature_names)\n",
    "\n",
    "    num_features = standardized_data.shape[1]\n",
    "    generator = Generator(wgan_hyperparams['latent_dim'], num_features).to(current_device)\n",
    "    critic = Critic(num_features).to(current_device)\n",
    "    optimizer_G = optim.Adam(generator.parameters(), lr=wgan_hyperparams['lr'], betas=(0.5, 0.9))\n",
    "    optimizer_C = optim.Adam(critic.parameters(), lr=wgan_hyperparams['lr'], betas=(0.5, 0.9))\n",
    "\n",
    "    print(f\"{log_prefix} 开始WGAN-GP训练 ({wgan_hyperparams['epochs']} 轮)...\")\n",
    "    for epoch in range(wgan_hyperparams['epochs']):\n",
    "        for i, (real_samples_batch,) in enumerate(dataloader):\n",
    "            if real_samples_batch.shape[0] == 0: continue\n",
    "            real_samples_batch = real_samples_batch.to(current_device)\n",
    "            current_real_batch_size = real_samples_batch.size(0)\n",
    "\n",
    "            for _ in range(wgan_hyperparams['n_critic']):\n",
    "                optimizer_C.zero_grad()\n",
    "                z = torch.randn(current_real_batch_size, wgan_hyperparams['latent_dim'], device=current_device)\n",
    "                fake_samples_batch = generator(z)\n",
    "                critic_real = critic(real_samples_batch)\n",
    "                critic_fake = critic(fake_samples_batch.detach())\n",
    "                gp = gradient_penalty(critic, real_samples_batch, fake_samples_batch, current_device)\n",
    "                critic_loss = torch.mean(critic_fake) - torch.mean(critic_real) + wgan_hyperparams['lambda_gp'] * gp\n",
    "                critic_loss.backward()\n",
    "                optimizer_C.step()\n",
    "            \n",
    "            optimizer_G.zero_grad()\n",
    "            z = torch.randn(current_real_batch_size, wgan_hyperparams['latent_dim'], device=current_device)\n",
    "            generated_for_g_loss = generator(z)\n",
    "            generator_loss = -torch.mean(critic(generated_for_g_loss))\n",
    "            generator_loss.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "        if (epoch + 1) % (max(1, wgan_hyperparams['epochs'] // 10)) == 0:\n",
    "             print(f\"{log_prefix} [Epoch {epoch+1}/{wgan_hyperparams['epochs']}] WGAN Critic Loss: {critic_loss.item():.4f}, Gen Loss: {generator_loss.item():.4f}\")\n",
    "    print(f\"{log_prefix} WGAN-GP训练完成。\")\n",
    "\n",
    "    print(f\"{log_prefix} 正在生成 {num_samples_to_generate} 个增强样本...\")\n",
    "    generator.eval()\n",
    "    generated_samples_list = []\n",
    "    remaining_samples = num_samples_to_generate\n",
    "    gen_batch_size = wgan_hyperparams['batch_size']\n",
    "    with torch.no_grad():\n",
    "        while remaining_samples > 0:\n",
    "            current_gen_size = min(gen_batch_size, remaining_samples)\n",
    "            z_generate = torch.randn(current_gen_size, wgan_hyperparams['latent_dim'], device=current_device)\n",
    "            generated_batch_std = generator(z_generate).detach().cpu().numpy()\n",
    "            generated_samples_list.append(generated_batch_std)\n",
    "            remaining_samples -= current_gen_size\n",
    "    generated_standardized_data_np = np.concatenate(generated_samples_list, axis=0)\n",
    "\n",
    "    generated_data_original_scale_np = generated_standardized_data_np * data_std + data_mean\n",
    "    generated_data_df = pd.DataFrame(generated_data_original_scale_np, columns=all_feature_names)\n",
    "\n",
    "    # if 'CHO' in generated_data_df.columns:\n",
    "    #     cho_column_generated = generated_data_df['CHO'].values\n",
    "    #     processed_cho = np.array([CHO_LEVELS[np.abs(CHO_LEVELS - val).argmin()] for val in cho_column_generated])\n",
    "    #     generated_data_df['CHO'] = processed_cho\n",
    "    for col_name in all_feature_names:\n",
    "        # if col_name == 'CHO': continue # <--- 删除或注释掉这一行，让CHO也参与通用裁剪\n",
    "        original_col_values = input_original_df[col_name]\n",
    "        col_min_original = original_col_values.min()\n",
    "        col_max_original = original_col_values.max()\n",
    "        col_range = col_max_original - col_min_original\n",
    "    \n",
    "        # 这部分原有的1%范围扩展逻辑是好的，保持不变\n",
    "        clip_min_for_col = col_min_original - 0.01 * col_range if col_range != 0 else col_min_original\n",
    "        clip_max_for_col = col_max_original + 0.01 * col_range if col_range != 0 else col_max_original\n",
    "    \n",
    "        # 在这里添加针对 CHO 和 PRO（以及其他您认为需要非负的列）的特殊处理\n",
    "        if col_name in ['CHO', 'PRO']: # 如果有其他列也需要确保非负，可以加入此列表\n",
    "            clip_min_for_col = max(0, clip_min_for_col)\n",
    "    \n",
    "        generated_data_df[col_name] = np.clip(generated_data_df[col_name], clip_min_for_col, clip_max_for_col)\n",
    "    print(f\"{log_prefix} 后处理完成。\")\n",
    "\n",
    "    if output_augmented_data_path:\n",
    "        try:\n",
    "            os.makedirs(os.path.dirname(output_augmented_data_path), exist_ok=True)\n",
    "            generated_data_df.to_excel(output_augmented_data_path, index=False)\n",
    "            print(f\"{log_prefix} 增强数据已保存到: {output_augmented_data_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"{log_prefix} 保存增强数据时发生错误: {e}\")\n",
    "    return generated_data_df\n",
    "\n",
    "# --- 3. BPNN 模型定义 (与之前的BPNN脚本一致) ---\n",
    "class BPNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, output_dim=1, dropout_rate=0.2):\n",
    "        super(BPNN, self).__init__()\n",
    "        layers = []\n",
    "        current_dim = input_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(current_dim, h_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            current_dim = h_dim\n",
    "        layers.append(nn.Linear(current_dim, output_dim))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# --- 4. BPNN 训练和评估函数 (与之前的BPNN脚本一致，但y_scaler是必须的) ---\n",
    "def train_evaluate_bpnn_fold(model_config, X_train_fold_scaled, y_train_fold_scaled,\n",
    "                              X_val_fold_scaled, y_val_fold_scaled, y_scaler_for_unnorm, # y_scaler用于反归一化MAE\n",
    "                              n_epochs, patience, current_device):\n",
    "    input_dim = X_train_fold_scaled.shape[1]\n",
    "    model = BPNN(input_dim, model_config['hidden_dims'], dropout_rate=model_config['dropout_rate']).to(current_device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=model_config['learning_rate'], weight_decay=model_config.get('weight_decay', 0))\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    train_dataset = TensorDataset(torch.FloatTensor(X_train_fold_scaled).to(current_device),\n",
    "                                  torch.FloatTensor(y_train_fold_scaled).reshape(-1,1).to(current_device))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=model_config['batch_size'], shuffle=True)\n",
    "    \n",
    "    val_dataset = TensorDataset(torch.FloatTensor(X_val_fold_scaled).to(current_device),\n",
    "                                torch.FloatTensor(y_val_fold_scaled).reshape(-1,1).to(current_device))\n",
    "    val_loader = DataLoader(val_dataset, batch_size=model_config['batch_size'], shuffle=False)\n",
    "\n",
    "    epoch_train_mae_unnormalized = []\n",
    "    epoch_val_mae_unnormalized = []\n",
    "    best_val_loss_mae_unnorm = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    # best_model_state = None # Storing best model state in memory\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        current_epoch_train_preds_unnorm = []\n",
    "        current_epoch_train_targets_unnorm = []\n",
    "        for batch_X, batch_y_scaled in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs_scaled = model(batch_X)\n",
    "            loss = criterion(outputs_scaled, batch_y_scaled)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_preds_unnorm = y_scaler_for_unnorm.inverse_transform(outputs_scaled.detach().cpu().numpy())\n",
    "            batch_targets_unnorm = y_scaler_for_unnorm.inverse_transform(batch_y_scaled.detach().cpu().numpy())\n",
    "            current_epoch_train_preds_unnorm.extend(batch_preds_unnorm.flatten())\n",
    "            current_epoch_train_targets_unnorm.extend(batch_targets_unnorm.flatten())\n",
    "        \n",
    "        epoch_train_mae_unnormalized.append(mean_absolute_error(current_epoch_train_targets_unnorm, current_epoch_train_preds_unnorm))\n",
    "\n",
    "        model.eval()\n",
    "        current_epoch_val_preds_unnorm = []\n",
    "        current_epoch_val_targets_unnorm = []\n",
    "        with torch.no_grad():\n",
    "            for batch_X_val, batch_y_val_scaled in val_loader:\n",
    "                val_outputs_scaled = model(batch_X_val)\n",
    "                batch_val_preds_unnorm = y_scaler_for_unnorm.inverse_transform(val_outputs_scaled.cpu().numpy())\n",
    "                batch_val_targets_unnorm = y_scaler_for_unnorm.inverse_transform(batch_y_val_scaled.cpu().numpy())\n",
    "                current_epoch_val_preds_unnorm.extend(batch_val_preds_unnorm.flatten())\n",
    "                current_epoch_val_targets_unnorm.extend(batch_val_targets_unnorm.flatten())\n",
    "        \n",
    "        current_val_mae_unnorm = mean_absolute_error(current_epoch_val_targets_unnorm, current_epoch_val_preds_unnorm)\n",
    "        epoch_val_mae_unnormalized.append(current_val_mae_unnorm)\n",
    "        \n",
    "        if current_val_mae_unnorm < best_val_loss_mae_unnorm:\n",
    "            best_val_loss_mae_unnorm = current_val_mae_unnorm\n",
    "            epochs_no_improve = 0\n",
    "            # best_model_state = model.state_dict() \n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "        \n",
    "        if epochs_no_improve >= patience:\n",
    "            # print(f\"  BPNN Early stopping at epoch {epoch+1}.\")\n",
    "            break\n",
    "            \n",
    "    # if best_model_state: model.load_state_dict(best_model_state) # Load best model for final evaluation\n",
    "\n",
    "    # Final evaluation on scaled validation set, then unscale\n",
    "    model.eval()\n",
    "    all_y_pred_val_scaled_list, all_y_val_scaled_list = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch_X_val, batch_y_val_s in val_loader:\n",
    "            val_outputs_s = model(batch_X_val)\n",
    "            all_y_pred_val_scaled_list.extend(val_outputs_s.cpu().numpy())\n",
    "            all_y_val_scaled_list.extend(batch_y_val_s.cpu().numpy())\n",
    "    y_pred_val_unnorm = y_scaler_for_unnorm.inverse_transform(np.array(all_y_pred_val_scaled_list)).flatten()\n",
    "    y_val_unnorm = y_scaler_for_unnorm.inverse_transform(np.array(all_y_val_scaled_list)).flatten()\n",
    "\n",
    "    # Final evaluation on scaled training set, then unscale\n",
    "    all_y_pred_train_scaled_list, all_y_train_scaled_list = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch_X_train, batch_y_train_s in train_loader:\n",
    "            train_outputs_s = model(batch_X_train)\n",
    "            all_y_pred_train_scaled_list.extend(train_outputs_s.cpu().numpy())\n",
    "            all_y_train_scaled_list.extend(batch_y_train_s.cpu().numpy())\n",
    "    y_pred_train_unnorm = y_scaler_for_unnorm.inverse_transform(np.array(all_y_pred_train_scaled_list)).flatten()\n",
    "    y_train_unnorm = y_scaler_for_unnorm.inverse_transform(np.array(all_y_train_scaled_list)).flatten()\n",
    "\n",
    "    return {\n",
    "        'model_state': model.state_dict(), # Return the state of the best performing model on this fold\n",
    "        'mae_val': mean_absolute_error(y_val_unnorm, y_pred_val_unnorm),\n",
    "        'rmse_val': np.sqrt(mean_squared_error(y_val_unnorm, y_pred_val_unnorm)),\n",
    "        'r2_val': r2_score(y_val_unnorm, y_pred_val_unnorm),\n",
    "        'mae_train': mean_absolute_error(y_train_unnorm, y_pred_train_unnorm),\n",
    "        'rmse_train': np.sqrt(mean_squared_error(y_train_unnorm, y_pred_train_unnorm)),\n",
    "        'r2_train': r2_score(y_train_unnorm, y_pred_train_unnorm),\n",
    "        'train_loss_curve_unnorm': epoch_train_mae_unnormalized,\n",
    "        'val_loss_curve_unnorm': epoch_val_mae_unnormalized\n",
    "    }\n",
    "\n",
    "# --- 5. 主流程开始 ---\n",
    "try:\n",
    "    development_df_original = pd.read_excel(DEV_SET_FILE)\n",
    "    final_test_df_original = pd.read_excel(TEST_SET_FILE)\n",
    "    print(f\"开发集形状: {development_df_original.shape}, 最终测试集形状: {final_test_df_original.shape}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"错误: 开发集或测试集文件未找到。请检查路径: {e}\")\n",
    "    exit()\n",
    "\n",
    "X_dev_original_df = development_df_original.drop(columns=[TARGET_COLUMN])\n",
    "y_dev_original_series = development_df_original[TARGET_COLUMN]\n",
    "X_final_test_df = final_test_df_original.drop(columns=[TARGET_COLUMN])\n",
    "y_final_test_series = final_test_df_original[TARGET_COLUMN]\n",
    "\n",
    "# --- 步骤一：BPNN 超参数调优 (使用WGAN-GP增强的开发集) ---\n",
    "print(\"\\n--- 步骤一：BPNN 超参数调优 (使用WGAN-GP增强数据) ---\")\n",
    "print(\"为BPNN HPO生成开发集的增强版本...\")\n",
    "num_augmented_samples_for_hpo = len(development_df_original) * 1 # 增强1倍数据量\n",
    "current_wgan_hpo_params = DEFAULT_WGAN_PARAMS.copy()\n",
    "current_wgan_hpo_params['epochs'] = DEFAULT_WGAN_PARAMS['epochs_for_final_hpo'] # 使用较多轮数训练GAN\n",
    "augmented_dev_for_hpo_output_path = os.path.join(AUGMENTED_DATA_OUTPUT_FOLDER, \"bpnn_augmented_dev_for_hpo.xlsx\")\n",
    "\n",
    "# WGAN-GP增强整个开发集\n",
    "augmented_dev_for_hpo_df = train_and_generate_wgangp(\n",
    "    input_original_df=development_df_original.copy(), # 传递包含目标列的完整DataFrame\n",
    "    target_col_name=TARGET_COLUMN,\n",
    "    wgan_hyperparams=current_wgan_hpo_params,\n",
    "    num_samples_to_generate=num_augmented_samples_for_hpo,\n",
    "    current_device=device,\n",
    "    fold_num_for_logging=\"BPNN_HPO_Dev_Set\",\n",
    "    output_augmented_data_path=augmented_dev_for_hpo_output_path\n",
    ")\n",
    "if augmented_dev_for_hpo_df.empty:\n",
    "    print(\"错误：为BPNN HPO生成的增强数据为空，无法继续。\")\n",
    "    exit()\n",
    "\n",
    "# 合并原始开发集和增强开发集，用于BPNN HPO\n",
    "X_aug_dev_hpo_df = augmented_dev_for_hpo_df.drop(columns=[TARGET_COLUMN])\n",
    "y_aug_dev_hpo_series = augmented_dev_for_hpo_df[TARGET_COLUMN]\n",
    "X_combined_dev_for_hpo_df = pd.concat([X_dev_original_df, X_aug_dev_hpo_df], ignore_index=True)\n",
    "y_combined_dev_for_hpo_series = pd.concat([y_dev_original_series, y_aug_dev_hpo_series], ignore_index=True)\n",
    "print(f\"用于BPNN HPO的总数据形状 (X): {X_combined_dev_for_hpo_df.shape}, (y): {y_combined_dev_for_hpo_series.shape}\")\n",
    "\n",
    "# BPNN HPO 开始\n",
    "print(\"开始BPNN超参数搜索 (在WGAN-GP增强数据上)...\")\n",
    "best_bpnn_params = None\n",
    "best_avg_hpo_val_mae = float('inf')\n",
    "hpo_results_log = []\n",
    "\n",
    "sampled_bpnn_configs = []\n",
    "for _ in range(N_ITER_BPNN_HPO):\n",
    "    config = {}\n",
    "    for key, values in BPNN_PARAM_GRID.items():\n",
    "        config[key] = random.choice(values)\n",
    "    if config not in sampled_bpnn_configs: # 避免重复 (可选)\n",
    "        sampled_bpnn_configs.append(config)\n",
    "\n",
    "print(f\"将尝试 {len(sampled_bpnn_configs)} 组BPNN超参数组合。\")\n",
    "\n",
    "# NumPy转换以提高效率，用于HPO的CV\n",
    "X_hpo_np = X_combined_dev_for_hpo_df.values\n",
    "y_hpo_np = y_combined_dev_for_hpo_series.values\n",
    "\n",
    "for i_config, current_bpnn_hpo_params in enumerate(sampled_bpnn_configs):\n",
    "    print(f\"\\n--- BPNN HPO 配置 {i_config+1}/{len(sampled_bpnn_configs)} ---\")\n",
    "    print(current_bpnn_hpo_params)\n",
    "    \n",
    "    kf_hpo = KFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE + i_config) # HPO内部用3折CV\n",
    "    fold_hpo_val_maes = []\n",
    "\n",
    "    for fold_idx_hpo, (train_idx_hpo, val_idx_hpo) in enumerate(kf_hpo.split(X_hpo_np, y_hpo_np)):\n",
    "        X_train_hpo_fold, X_val_hpo_fold = X_hpo_np[train_idx_hpo], X_hpo_np[val_idx_hpo]\n",
    "        y_train_hpo_fold, y_val_hpo_fold = y_hpo_np[train_idx_hpo], y_hpo_np[val_idx_hpo]\n",
    "\n",
    "        # BPNN HPO内部的特征和目标缩放\n",
    "        x_scaler_hpo_fold = StandardScaler().fit(X_train_hpo_fold)\n",
    "        X_train_hpo_fold_scaled = x_scaler_hpo_fold.transform(X_train_hpo_fold)\n",
    "        X_val_hpo_fold_scaled = x_scaler_hpo_fold.transform(X_val_hpo_fold)\n",
    "\n",
    "        y_scaler_hpo_fold = StandardScaler().fit(y_train_hpo_fold.reshape(-1, 1))\n",
    "        y_train_hpo_fold_scaled = y_scaler_hpo_fold.transform(y_train_hpo_fold.reshape(-1, 1)).flatten()\n",
    "        y_val_hpo_fold_scaled = y_scaler_hpo_fold.transform(y_val_hpo_fold.reshape(-1, 1)).flatten()\n",
    "        \n",
    "        hpo_fold_results = train_evaluate_bpnn_fold(\n",
    "            current_bpnn_hpo_params, X_train_hpo_fold_scaled, y_train_hpo_fold_scaled,\n",
    "            X_val_hpo_fold_scaled, y_val_hpo_fold_scaled, y_scaler_hpo_fold, # 传递y_scaler\n",
    "            n_epochs=EPOCHS_BPNN_HPO, patience=PATIENCE_BPNN_HPO, current_device=device\n",
    "        )\n",
    "        fold_hpo_val_maes.append(hpo_fold_results['mae_val'])\n",
    "    \n",
    "    avg_hpo_fold_val_mae = np.mean(fold_hpo_val_maes)\n",
    "    hpo_results_log.append({'params': current_bpnn_hpo_params, 'avg_val_mae': avg_hpo_fold_val_mae})\n",
    "    print(f\"BPNN HPO 配置 {i_config+1} 平均验证 MAE: {avg_hpo_fold_val_mae:.4f}\")\n",
    "\n",
    "    if avg_hpo_fold_val_mae < best_avg_hpo_val_mae:\n",
    "        best_avg_hpo_val_mae = avg_hpo_fold_val_mae\n",
    "        best_bpnn_params = current_bpnn_hpo_params\n",
    "\n",
    "print(\"\\n--- BPNN 超参数调优完成 ---\")\n",
    "if best_bpnn_params:\n",
    "    print(f\"找到的最佳BPNN超参数: {best_bpnn_params}\")\n",
    "    print(f\"最佳BPNN HPO平均验证 MAE: {best_avg_hpo_val_mae:.4f}\")\n",
    "else:\n",
    "    print(\"错误：未能找到最佳BPNN参数。将使用第一组尝试的参数。\")\n",
    "    best_bpnn_params = sampled_bpnn_configs[0] if sampled_bpnn_configs else BPNN_PARAM_GRID[0]\n",
    "\n",
    "\n",
    "# --- 步骤二：K-折交叉验证 (BPNN + 动态WGAN-GP增强) ---\n",
    "print(f\"\\n--- 步骤二：在开发集上进行 {N_SPLITS_KFOLD}-折交叉验证 (BPNN + 动态WGAN-GP增强) ---\")\n",
    "kf_cv = KFold(n_splits=N_SPLITS_KFOLD, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "kfold_cv_val_metrics_list_bpnn = []\n",
    "kfold_cv_train_metrics_list_bpnn = []\n",
    "cv_bpnn_train_mae_curves_unnorm = []\n",
    "cv_bpnn_val_mae_curves_unnorm = []\n",
    "\n",
    "current_wgan_cv_params = DEFAULT_WGAN_PARAMS.copy()\n",
    "current_wgan_cv_params['epochs'] = DEFAULT_WGAN_PARAMS['epochs_for_cv'] # CV内部用较少轮数训练GAN\n",
    "augmentation_factor_cv = 1 # CV每折增强1倍数据量\n",
    "\n",
    "for fold_idx_cv, (train_indices_cv, val_indices_cv) in enumerate(kf_cv.split(development_df_original)):\n",
    "    print(f\"\\n--- BPNN K-Fold: 第 {fold_idx_cv + 1}/{N_SPLITS_KFOLD} 折 ---\")\n",
    "    cv_train_original_fold_df = development_df_original.iloc[train_indices_cv]\n",
    "    cv_val_original_fold_df = development_df_original.iloc[val_indices_cv]\n",
    "\n",
    "    X_cv_val_fold_df = cv_val_original_fold_df.drop(columns=[TARGET_COLUMN])\n",
    "    y_cv_val_fold_series = cv_val_original_fold_df[TARGET_COLUMN]\n",
    "\n",
    "    print(f\"当前CV训练集（原始）形状: {cv_train_original_fold_df.shape}\")\n",
    "    num_augmented_samples_cv_fold = len(cv_train_original_fold_df) * augmentation_factor_cv\n",
    "    \n",
    "    dynamic_wgan_cv_params = current_wgan_cv_params.copy()\n",
    "    # 动态调整GAN的batch_size以适应可能较小的CV训练折数据\n",
    "    dynamic_wgan_cv_params['batch_size'] = min(current_wgan_cv_params['batch_size'], max(1, len(cv_train_original_fold_df) // 2 if len(cv_train_original_fold_df) > 1 else 1))\n",
    "    \n",
    "    # 为当前CV训练折动态生成WGAN-GP增强数据\n",
    "    cv_augmented_fold_df = train_and_generate_wgangp(\n",
    "        input_original_df=cv_train_original_fold_df.copy(), # GAN训练基于当前折的原始训练数据\n",
    "        target_col_name=TARGET_COLUMN,\n",
    "        wgan_hyperparams=dynamic_wgan_cv_params,\n",
    "        num_samples_to_generate=num_augmented_samples_cv_fold,\n",
    "        current_device=device,\n",
    "        fold_num_for_logging=(fold_idx_cv + 1),\n",
    "        output_augmented_data_path=None # CV内部一般不保存增强数据文件\n",
    "    )\n",
    "    if cv_augmented_fold_df.empty:\n",
    "        print(f\"警告：Fold {fold_idx_cv + 1} 的WGAN-GP增强数据为空，跳过此折的BPNN训练。\")\n",
    "        cv_bpnn_train_mae_curves_unnorm.append([])\n",
    "        cv_bpnn_val_mae_curves_unnorm.append([])\n",
    "        continue\n",
    "\n",
    "    # 合并当前CV折的原始训练数据和增强数据\n",
    "    X_cv_train_original_fold_df = cv_train_original_fold_df.drop(columns=[TARGET_COLUMN])\n",
    "    y_cv_train_original_fold_series = cv_train_original_fold_df[TARGET_COLUMN]\n",
    "    X_cv_augmented_fold_df = cv_augmented_fold_df.drop(columns=[TARGET_COLUMN])\n",
    "    y_cv_augmented_fold_series = cv_augmented_fold_df[TARGET_COLUMN]\n",
    "\n",
    "    X_cv_train_combined_fold_df = pd.concat([X_cv_train_original_fold_df, X_cv_augmented_fold_df], ignore_index=True)\n",
    "    y_cv_train_combined_fold_series = pd.concat([y_cv_train_original_fold_series, y_cv_augmented_fold_series], ignore_index=True)\n",
    "    print(f\"当前CV训练集（原始+增强后）形状 (X): {X_cv_train_combined_fold_df.shape}, (y): {y_cv_train_combined_fold_series.shape}\")\n",
    "\n",
    "    # BPNN的特征和目标缩放（基于当前合并后的CV训练折数据）\n",
    "    x_scaler_cv_fold = StandardScaler().fit(X_cv_train_combined_fold_df.values)\n",
    "    X_cv_train_combined_fold_scaled = x_scaler_cv_fold.transform(X_cv_train_combined_fold_df.values)\n",
    "    X_cv_val_fold_scaled = x_scaler_cv_fold.transform(X_cv_val_fold_df.values) # 用训练集的scaler转换验证集\n",
    "\n",
    "    y_scaler_cv_fold = StandardScaler().fit(y_cv_train_combined_fold_series.values.reshape(-1, 1))\n",
    "    y_cv_train_combined_fold_scaled = y_scaler_cv_fold.transform(y_cv_train_combined_fold_series.values.reshape(-1, 1)).flatten()\n",
    "    y_cv_val_fold_scaled = y_scaler_cv_fold.transform(y_cv_val_fold_series.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "    print(f\"Fold {fold_idx_cv + 1}: 开始训练BPNN模型...\")\n",
    "    bpnn_fold_results = train_evaluate_bpnn_fold(\n",
    "        best_bpnn_params, X_cv_train_combined_fold_scaled, y_cv_train_combined_fold_scaled,\n",
    "        X_cv_val_fold_scaled, y_cv_val_fold_scaled, y_scaler_cv_fold, # 传递y_scaler\n",
    "        n_epochs=EPOCHS_BPNN_CV_FINAL, patience=PATIENCE_BPNN_CV_FINAL, current_device=device\n",
    "    )\n",
    "    \n",
    "    kfold_cv_val_metrics_list_bpnn.append({'fold': fold_idx_cv + 1, 'MAE': bpnn_fold_results['mae_val'], 'RMSE': bpnn_fold_results['rmse_val'], 'R2': bpnn_fold_results['r2_val']})\n",
    "    kfold_cv_train_metrics_list_bpnn.append({'fold': fold_idx_cv + 1, 'MAE': bpnn_fold_results['mae_train'], 'RMSE': bpnn_fold_results['rmse_train'], 'R2': bpnn_fold_results['r2_train']})\n",
    "    cv_bpnn_train_mae_curves_unnorm.append(bpnn_fold_results['train_loss_curve_unnorm'])\n",
    "    cv_bpnn_val_mae_curves_unnorm.append(bpnn_fold_results['val_loss_curve_unnorm'])\n",
    "    \n",
    "    print(f\"Fold {fold_idx_cv + 1} - BPNN CV Train MAE: {bpnn_fold_results['mae_train']:.4f}, R2: {bpnn_fold_results['r2_train']:.4f} | BPNN CV Val MAE: {bpnn_fold_results['mae_val']:.4f}, R2: {bpnn_fold_results['r2_val']:.4f}\")\n",
    "\n",
    "avg_kfold_cv_val_metrics_bpnn_df = pd.DataFrame(kfold_cv_val_metrics_list_bpnn)\n",
    "print(\"\\n--- BPNN K-折交叉验证平均CV验证性能 (开发集, WGAN-GP动态增强) ---\")\n",
    "if not avg_kfold_cv_val_metrics_bpnn_df.empty:\n",
    "    avg_mae_cv_val_bpnn = avg_kfold_cv_val_metrics_bpnn_df['MAE'].mean()\n",
    "    avg_rmse_cv_val_bpnn = avg_kfold_cv_val_metrics_bpnn_df['RMSE'].mean()\n",
    "    avg_r2_cv_val_bpnn = avg_kfold_cv_val_metrics_bpnn_df['R2'].mean()\n",
    "    print(f\"BPNN 平均 CV 验证集 MAE: {avg_mae_cv_val_bpnn:.4f}, RMSE: {avg_rmse_cv_val_bpnn:.4f}, R2: {avg_r2_cv_val_bpnn:.4f}\")\n",
    "else:\n",
    "    print(\"BPNN K-Fold CV验证结果为空。\")\n",
    "    avg_mae_cv_val_bpnn, avg_r2_cv_val_bpnn = np.nan, np.nan\n",
    "\n",
    "avg_kfold_cv_train_metrics_bpnn_df = pd.DataFrame(kfold_cv_train_metrics_list_bpnn)\n",
    "print(\"\\n--- BPNN K-折交叉验证平均CV训练性能 (开发集, WGAN-GP动态增强) ---\")\n",
    "if not avg_kfold_cv_train_metrics_bpnn_df.empty:\n",
    "    avg_mae_cv_train_bpnn = avg_kfold_cv_train_metrics_bpnn_df['MAE'].mean()\n",
    "    avg_r2_cv_train_bpnn = avg_kfold_cv_train_metrics_bpnn_df['R2'].mean()\n",
    "    print(f\"BPNN 平均 CV 训练集 MAE: {avg_mae_cv_train_bpnn:.4f}, R2: {avg_r2_cv_train_bpnn:.4f}\")\n",
    "else:\n",
    "    print(\"BPNN K-Fold CV训练结果为空。\")\n",
    "    avg_mae_cv_train_bpnn, avg_r2_cv_train_bpnn = np.nan, np.nan\n",
    "\n",
    "# 绘制BPNN的K-Fold CV性能图表\n",
    "if not np.isnan(avg_mae_cv_val_bpnn) and not np.isnan(avg_mae_cv_train_bpnn):\n",
    "    print(\"\\n--- 步骤二结束：生成BPNN K-Fold CV性能图表 ---\")\n",
    "    metrics_plot_names_en = ['MAE', 'R2 Score']\n",
    "    values_cv_val_plot_bpnn = [avg_mae_cv_val_bpnn, avg_r2_cv_val_bpnn]\n",
    "    values_cv_train_plot_bpnn = [avg_mae_cv_train_bpnn, avg_r2_cv_train_bpnn]\n",
    "    x_axis_plot = np.arange(len(metrics_plot_names_en))\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(x_axis_plot - 0.2, values_cv_train_plot_bpnn, width=0.4, label='BPNN CV Train Avg.', align='center')\n",
    "    plt.bar(x_axis_plot + 0.2, values_cv_val_plot_bpnn, width=0.4, label='BPNN CV Validation Avg.', align='center')\n",
    "    plt.xticks(x_axis_plot, metrics_plot_names_en)\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('BPNN Average K-Fold CV Metrics (WGAN-GP Augmented)')\n",
    "    plt.legend(); plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plot_filename_metrics_bpnn = os.path.join(OUTPUT_PLOT_PATH, \"bpnn_wgan_kfold_avg_eval_metrics.png\")\n",
    "    try: plt.savefig(plot_filename_metrics_bpnn, dpi=300, bbox_inches='tight'); print(f\"BPNN图表1已保存: {plot_filename_metrics_bpnn}\")\n",
    "    except Exception as e: print(f\"保存BPNN图表1错误: {e}\")\n",
    "    plt.show()\n",
    "\n",
    "    if any(cv_bpnn_train_mae_curves_unnorm) and any(cv_bpnn_val_mae_curves_unnorm):\n",
    "        plt.figure(figsize=(14, 7))\n",
    "        max_epochs_cv_bpnn = 0\n",
    "        for i in range(len(cv_bpnn_train_mae_curves_unnorm)):\n",
    "            if cv_bpnn_train_mae_curves_unnorm[i] and cv_bpnn_val_mae_curves_unnorm[i]:\n",
    "                epochs_this_fold = len(cv_bpnn_train_mae_curves_unnorm[i])\n",
    "                max_epochs_cv_bpnn = max(max_epochs_cv_bpnn, epochs_this_fold)\n",
    "                plt.plot(range(1, epochs_this_fold + 1), cv_bpnn_train_mae_curves_unnorm[i], label=f'BPNN CV Train Fold {i+1}', linestyle='-')\n",
    "                plt.plot(range(1, epochs_this_fold + 1), cv_bpnn_val_mae_curves_unnorm[i], label=f'BPNN CV Val Fold {i+1}', linestyle='--')\n",
    "        plt.xlabel('Epoch'); plt.ylabel('Mean Absolute Error (MAE) - Unnormalized')\n",
    "        plt.title('BPNN Training and CV Validation MAE (Unnormalized) per Fold (WGAN-GP Augmented)')\n",
    "        if max_epochs_cv_bpnn > 0: plt.xlim(1, max_epochs_cv_bpnn)\n",
    "        if len(cv_bpnn_train_mae_curves_unnorm) <= 5: plt.legend(loc='upper right')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plot_filename_loss_bpnn = os.path.join(OUTPUT_PLOT_PATH, \"bpnn_wgan_kfold_mae_loss_per_fold.png\")\n",
    "        try: plt.savefig(plot_filename_loss_bpnn, dpi=300, bbox_inches='tight'); print(f\"BPNN图表2已保存: {plot_filename_loss_bpnn}\")\n",
    "        except Exception as e: print(f\"保存BPNN图表2错误: {e}\")\n",
    "        plt.show()\n",
    "    else: print(\"没有收集到足够的BPNN MAE曲线数据用于绘制图表2。\")\n",
    "else: print(\"由于BPNN K-Fold平均结果为空或NaN，跳过图表绘制。\")\n",
    "\n",
    "\n",
    "# --- 步骤三：训练最终BPNN模型 ---\n",
    "print(\"\\n--- 步骤三：训练最终BPNN模型 (使用WGAN-GP增强的完整开发集) ---\")\n",
    "print(\"为最终BPNN模型生成开发集的完整增强版本...\")\n",
    "final_wgan_params_bpnn = DEFAULT_WGAN_PARAMS.copy()\n",
    "final_wgan_params_bpnn['epochs'] = DEFAULT_WGAN_PARAMS['epochs_for_final_hpo'] # 使用与HPO时相同的GAN轮数\n",
    "num_augmented_samples_final_bpnn = len(development_df_original) * 2 # 最终模型增强2倍数据量\n",
    "final_augmented_dev_output_path_bpnn = os.path.join(AUGMENTED_DATA_OUTPUT_FOLDER, \"bpnn_augmented_dev_for_final_model.xlsx\")\n",
    "\n",
    "final_augmented_dev_df_bpnn = train_and_generate_wgangp(\n",
    "    input_original_df=development_df_original.copy(),\n",
    "    target_col_name=TARGET_COLUMN,\n",
    "    wgan_hyperparams=final_wgan_params_bpnn,\n",
    "    num_samples_to_generate=num_augmented_samples_final_bpnn,\n",
    "    current_device=device,\n",
    "    fold_num_for_logging=\"BPNN_Final_Dev_Set_Augmentation\",\n",
    "    output_augmented_data_path=final_augmented_dev_output_path_bpnn\n",
    ")\n",
    "if final_augmented_dev_df_bpnn.empty:\n",
    "    print(\"错误：为最终BPNN模型生成的WGAN-GP增强数据为空。\")\n",
    "    exit()\n",
    "\n",
    "# 合并原始开发集和最终增强数据\n",
    "X_final_aug_dev_df = final_augmented_dev_df_bpnn.drop(columns=[TARGET_COLUMN])\n",
    "y_final_aug_dev_series = final_augmented_dev_df_bpnn[TARGET_COLUMN]\n",
    "X_train_final_model_df = pd.concat([X_dev_original_df, X_final_aug_dev_df], ignore_index=True)\n",
    "y_train_final_model_series = pd.concat([y_dev_original_series, y_final_aug_dev_series], ignore_index=True)\n",
    "print(f\"用于训练最终BPNN模型的总数据形状 (X): {X_train_final_model_df.shape}, (y): {y_train_final_model_series.shape}\")\n",
    "\n",
    "# 为最终BPNN模型准备数据和缩放器\n",
    "x_scaler_final_bpnn = StandardScaler().fit(X_train_final_model_df.values)\n",
    "X_train_final_model_scaled = x_scaler_final_bpnn.transform(X_train_final_model_df.values)\n",
    "\n",
    "y_scaler_final_bpnn = StandardScaler().fit(y_train_final_model_series.values.reshape(-1, 1))\n",
    "y_train_final_model_scaled = y_scaler_final_bpnn.transform(y_train_final_model_series.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# 最终模型训练，也使用一部分数据做早停验证\n",
    "if len(X_train_final_model_scaled) > 10:\n",
    "    X_fm_train_s, X_fm_val_s, y_fm_train_s, y_fm_val_s = train_test_split(\n",
    "        X_train_final_model_scaled, y_train_final_model_scaled, test_size=0.1, random_state=RANDOM_STATE\n",
    "    )\n",
    "else: # 数据太少，不用验证集\n",
    "    X_fm_train_s, y_fm_train_s = X_train_final_model_scaled, y_train_final_model_scaled\n",
    "    X_fm_val_s, y_fm_val_s = X_train_final_model_scaled, y_train_final_model_scaled # 用自身做名义上的验证\n",
    "\n",
    "print(\"开始训练最终BPNN模型...\")\n",
    "final_bpnn_model_results = train_evaluate_bpnn_fold(\n",
    "    best_bpnn_params, X_fm_train_s, y_fm_train_s,\n",
    "    X_fm_val_s, y_fm_val_s, y_scaler_final_bpnn, # 使用最终的y_scaler\n",
    "    n_epochs=EPOCHS_BPNN_CV_FINAL, patience=PATIENCE_BPNN_CV_FINAL, current_device=device\n",
    ")\n",
    "print(\"最终BPNN模型训练完成。\")\n",
    "\n",
    "final_bpnn_model_path = os.path.join(MODEL_OUTPUT_PATH, \"final_bpnn_wgangp_model.pth\")\n",
    "torch.save(final_bpnn_model_results['model_state'], final_bpnn_model_path) # 保存模型参数\n",
    "# 保存用于最终测试集预测的scalers\n",
    "joblib.dump(x_scaler_final_bpnn, os.path.join(MODEL_OUTPUT_PATH, \"final_bpnn_x_scaler.joblib\"))\n",
    "joblib.dump(y_scaler_final_bpnn, os.path.join(MODEL_OUTPUT_PATH, \"final_bpnn_y_scaler.joblib\"))\n",
    "print(f\"最终BPNN模型参数已保存到: {final_bpnn_model_path}\")\n",
    "print(f\"最终BPNN X/Y Scalers 已保存到: {MODEL_OUTPUT_PATH}\")\n",
    "\n",
    "# --- 步骤四：最终无偏评估 (在“最终测试集”上) ---\n",
    "print(\"\\n--- 步骤四：在最终测试集上进行BPNN无偏评估 ---\")\n",
    "# 加载最终BPNN模型和scalers\n",
    "final_bpnn_model_loaded = BPNN(X_final_test_df.shape[1], best_bpnn_params['hidden_dims'], dropout_rate=best_bpnn_params['dropout_rate']).to(device)\n",
    "final_bpnn_model_loaded.load_state_dict(torch.load(final_bpnn_model_path, map_location=device))\n",
    "final_bpnn_model_loaded.eval()\n",
    "\n",
    "x_scaler_final_loaded = joblib.load(os.path.join(MODEL_OUTPUT_PATH, \"final_bpnn_x_scaler.joblib\"))\n",
    "y_scaler_final_loaded = joblib.load(os.path.join(MODEL_OUTPUT_PATH, \"final_bpnn_y_scaler.joblib\"))\n",
    "\n",
    "# 准备测试集数据\n",
    "X_final_test_scaled = x_scaler_final_loaded.transform(X_final_test_df.values)\n",
    "X_final_test_tensor = torch.FloatTensor(X_final_test_scaled).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred_final_test_scaled_tensor = final_bpnn_model_loaded(X_final_test_tensor)\n",
    "y_pred_final_test_scaled_np = y_pred_final_test_scaled_tensor.cpu().numpy()\n",
    "y_pred_final_test_unnorm = y_scaler_final_loaded.inverse_transform(y_pred_final_test_scaled_np).flatten()\n",
    "\n",
    "mae_final_bpnn = mean_absolute_error(y_final_test_series.values, y_pred_final_test_unnorm)\n",
    "rmse_final_bpnn = np.sqrt(mean_squared_error(y_final_test_series.values, y_pred_final_test_unnorm))\n",
    "r2_final_bpnn = r2_score(y_final_test_series.values, y_pred_final_test_unnorm)\n",
    "print(\"--- 最终BPNN模型在最终测试集上的性能 ---\")\n",
    "print(f\"MAE: {mae_final_bpnn:.4f}, RMSE: {rmse_final_bpnn:.4f}, R2 Score: {r2_final_bpnn:.4f}\")\n",
    "\n",
    "# 绘制最终测试集 真实值 vs 预测值 图\n",
    "print(\"\\n--- 步骤四结束：生成BPNN最终测试集真实值 vs 预测值图 ---\")\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(y_final_test_series.values, y_pred_final_test_unnorm, alpha=0.7, edgecolors='w', linewidth=0.5)\n",
    "min_val = min(y_final_test_series.min(), y_pred_final_test_unnorm.min())\n",
    "max_val = max(y_final_test_series.max(), y_pred_final_test_unnorm.max())\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'k--', lw=2)\n",
    "plt.xlabel('Actual Rowing Distance'); plt.ylabel('Predicted Rowing Distance (BPNN)')\n",
    "plt.title('BPNN Final Model (WGAN-GP Aug): Actual vs. Predicted (Test Set)')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plot_filename_actual_vs_pred_bpnn = os.path.join(OUTPUT_PLOT_PATH, \"bpnn_wgan_final_actual_vs_predicted.png\")\n",
    "try: plt.savefig(plot_filename_actual_vs_pred_bpnn, dpi=300, bbox_inches='tight'); print(f\"BPNN最终测试图已保存: {plot_filename_actual_vs_pred_bpnn}\")\n",
    "except Exception as e: print(f\"保存BPNN最终测试图错误: {e}\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n--- BPNN + WGAN-GP 整体流程执行完毕 ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6697dc76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (xgb_gpu_env)",
   "language": "python",
   "name": "xgb_gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
