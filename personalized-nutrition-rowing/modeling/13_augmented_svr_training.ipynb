{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade2f92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import joblib\n",
    "from pathlib import Path \n",
    "CURRENT_DIR = Path.cwd()\n",
    "PROJECT_ROOT = CURRENT_DIR.parent\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"output\"\n",
    "\n",
    "# --- 0. 全局配置 ---\n",
    "# 数据路径\n",
    "BASE_DATA_PATH = DATA_DIR\n",
    "DEV_SET_FILE = DATA_DIR / \"development_set_selected_features.xlsx\"\n",
    "TEST_SET_FILE = DATA_DIR / \"final_test_set_selected_features.xlsx\"\n",
    "AUGMENTED_DATA_OUTPUT_FOLDER = DATA_DIR / \"augmented_outputs_svr\"# 保存中间增强数据 (SVR)\n",
    "MODEL_OUTPUT_PATH = DATA_DIR / \"trained_models_svr\" # 保存训练好的模型 (SVR)\n",
    "OUTPUT_PLOT_PATH = OUTPUT_DIR # 图表导出路径\n",
    "\n",
    "os.makedirs(AUGMENTED_DATA_OUTPUT_FOLDER, exist_ok=True)\n",
    "os.makedirs(MODEL_OUTPUT_PATH, exist_ok=True)\n",
    "os.makedirs(OUTPUT_PLOT_PATH, exist_ok=True)\n",
    "\n",
    "TARGET_COLUMN = 'Rowing distance'\n",
    "RANDOM_STATE = 42\n",
    "N_SPLITS_KFOLD = 5\n",
    "\n",
    "# WGAN-GP 预设参数 (与之前相同)\n",
    "# CHO_LEVELS = np.array([0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2])\n",
    "DEFAULT_WGAN_PARAMS = {\n",
    "    'latent_dim': 100,\n",
    "    'lambda_gp': 10,\n",
    "    'n_critic': 5,\n",
    "    'lr': 0.00005, # WGAN-GP的学习率\n",
    "    'batch_size': 32,\n",
    "    'epochs_for_cv': 500, # K-Fold内部动态增强时WGAN的轮数\n",
    "    'epochs_for_final': 2000 # 用于最终增强或HPO时WGAN的轮数 (可调整)\n",
    "}\n",
    "\n",
    "# SVR RandomizedSearchCV 参数网格\n",
    "SVR_PARAM_GRID = {\n",
    "    'svr__kernel': ['rbf', 'linear', 'poly'],\n",
    "    'svr__C': [0.1, 1, 10, 50, 100, 200, 500], # 调整范围\n",
    "    'svr__gamma': ['scale', 'auto', 0.001, 0.005, 0.01, 0.05, 0.1], # 调整范围\n",
    "    'svr__epsilon': [0.01, 0.05, 0.1, 0.15, 0.2, 0.3], # 调整范围\n",
    "    'svr__degree': [2, 3] # 仅对 poly 核\n",
    "}\n",
    "N_ITER_RANDOMIZED_SEARCH = 50 # RandomizedSearchCV的迭代次数 (可增加)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"将使用设备: {device}\")\n",
    "\n",
    "# --- 1. WGAN-GP 模型定义 (与之前相同) ---\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128), nn.ReLU(),\n",
    "            nn.Linear(128, 256), nn.ReLU(),\n",
    "            nn.Linear(256, 512), nn.ReLU(),\n",
    "            nn.Linear(512, output_dim)\n",
    "        )\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Critic, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512), nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256), nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 128), nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "def gradient_penalty(critic_model, real_samples, fake_samples, device_in_use):\n",
    "    batch_size_gp = real_samples.size(0)\n",
    "    alpha = torch.rand(batch_size_gp, 1, device=device_in_use).expand_as(real_samples)\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "    d_interpolates = critic_model(interpolates)\n",
    "    fake_grad_output = torch.ones_like(d_interpolates, device=device_in_use)\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=d_interpolates, inputs=interpolates, grad_outputs=fake_grad_output,\n",
    "        create_graph=True, retain_graph=True, only_inputs=True\n",
    "    )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty_val = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty_val\n",
    "\n",
    "# --- 2. WGAN-GP 训练与生成辅助函数 (基本与之前相同) ---\n",
    "def train_and_generate_wgangp(input_original_df,\n",
    "                              target_col_name,\n",
    "                              wgan_hyperparams,\n",
    "                              num_samples_to_generate,\n",
    "                              current_device,\n",
    "                              fold_num_for_logging=None,\n",
    "                              output_augmented_data_path=None):\n",
    "    # 此函数内部逻辑与XGBoost版本中的WGAN-GP部分基本一致\n",
    "    # WGAN-GP本身进行标准化，生成后反标准化回原始尺度\n",
    "    # 所以输出的 augmented_data_df 是在原始数据尺度上的\n",
    "\n",
    "    log_prefix = f\"[WGAN-GP\"\n",
    "    if isinstance(fold_num_for_logging, int):\n",
    "        log_prefix += f\" Fold {fold_num_for_logging}\"\n",
    "    elif isinstance(fold_num_for_logging, str):\n",
    "        log_prefix += f\" Stage {fold_num_for_logging}\"\n",
    "    log_prefix += \"]\"\n",
    "\n",
    "    print(f\"\\n{log_prefix} 开始处理，输入数据形状: {input_original_df.shape}\")\n",
    "\n",
    "    all_feature_names = input_original_df.columns.tolist()\n",
    "    original_data_values = input_original_df.values.astype(np.float32)\n",
    "\n",
    "    data_mean = np.mean(original_data_values, axis=0)\n",
    "    data_std = np.std(original_data_values, axis=0)\n",
    "    data_std[data_std == 0] = 1\n",
    "    standardized_data = (original_data_values - data_mean) / data_std\n",
    "\n",
    "    data_tensor = torch.tensor(standardized_data)\n",
    "    dataset = TensorDataset(data_tensor)\n",
    "    \n",
    "    current_batch_size = min(wgan_hyperparams['batch_size'], len(dataset))\n",
    "    if current_batch_size == 0:\n",
    "        print(f\"{log_prefix} 错误：数据集为空或过小 ({len(dataset)} samples), 无法创建DataLoader。\")\n",
    "        return pd.DataFrame(columns=all_feature_names)\n",
    "    \n",
    "    use_drop_last = len(dataset) >= current_batch_size * 2\n",
    "    dataloader = DataLoader(dataset, batch_size=current_batch_size, shuffle=True, drop_last=use_drop_last)\n",
    "    \n",
    "    if len(dataloader) == 0 and len(dataset) > 0:\n",
    "        print(f\"{log_prefix} 警告: DataLoader为空，但输入数据集不为空。将尝试 drop_last=False\")\n",
    "        dataloader = DataLoader(dataset, batch_size=current_batch_size, shuffle=True, drop_last=False)\n",
    "        if len(dataloader) == 0 and len(dataset) > 0:\n",
    "             print(f\"{log_prefix} 错误: DataLoader仍然为空。无法继续GAN训练。\")\n",
    "             return pd.DataFrame(columns=all_feature_names)\n",
    "\n",
    "    num_features = standardized_data.shape[1]\n",
    "    generator = Generator(wgan_hyperparams['latent_dim'], num_features).to(current_device)\n",
    "    critic = Critic(num_features).to(current_device)\n",
    "    optimizer_G = optim.Adam(generator.parameters(), lr=wgan_hyperparams['lr'], betas=(0.5, 0.9))\n",
    "    optimizer_C = optim.Adam(critic.parameters(), lr=wgan_hyperparams['lr'], betas=(0.5, 0.9))\n",
    "\n",
    "    print(f\"{log_prefix} 开始WGAN-GP训练 ({wgan_hyperparams['epochs']} 轮)...\")\n",
    "    critic_loss_val, generator_loss_val = torch.tensor(0.0), torch.tensor(0.0)\n",
    "    for epoch in range(wgan_hyperparams['epochs']):\n",
    "        for i, (real_samples_batch,) in enumerate(dataloader):\n",
    "            if real_samples_batch.shape[0] == 0: continue\n",
    "            real_samples_batch = real_samples_batch.to(current_device)\n",
    "            current_real_batch_size = real_samples_batch.size(0)\n",
    "\n",
    "            for _ in range(wgan_hyperparams['n_critic']):\n",
    "                optimizer_C.zero_grad()\n",
    "                z = torch.randn(current_real_batch_size, wgan_hyperparams['latent_dim'], device=current_device)\n",
    "                fake_samples_batch = generator(z)\n",
    "                critic_real = critic(real_samples_batch)\n",
    "                critic_fake = critic(fake_samples_batch.detach())\n",
    "                gp = gradient_penalty(critic, real_samples_batch, fake_samples_batch, current_device)\n",
    "                critic_loss = torch.mean(critic_fake) - torch.mean(critic_real) + wgan_hyperparams['lambda_gp'] * gp\n",
    "                critic_loss.backward()\n",
    "                optimizer_C.step()\n",
    "                critic_loss_val = critic_loss\n",
    "            \n",
    "            optimizer_G.zero_grad()\n",
    "            z = torch.randn(current_real_batch_size, wgan_hyperparams['latent_dim'], device=current_device)\n",
    "            generated_for_g_loss = generator(z)\n",
    "            generator_loss = -torch.mean(critic(generated_for_g_loss))\n",
    "            generator_loss.backward()\n",
    "            optimizer_G.step()\n",
    "            generator_loss_val = generator_loss\n",
    "\n",
    "        if (epoch + 1) % (max(1, wgan_hyperparams['epochs'] // 10)) == 0:\n",
    "             print(f\"{log_prefix} [Epoch {epoch+1}/{wgan_hyperparams['epochs']}] Critic Loss: {critic_loss_val.item():.4f}, Gen Loss: {generator_loss_val.item():.4f}\")\n",
    "\n",
    "    print(f\"{log_prefix} WGAN-GP训练完成。\")\n",
    "    print(f\"{log_prefix} 正在生成 {num_samples_to_generate} 个增强样本...\")\n",
    "    generator.eval()\n",
    "    generated_samples_list = []\n",
    "    remaining_samples = num_samples_to_generate\n",
    "    gen_batch_size = wgan_hyperparams['batch_size']\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        while remaining_samples > 0:\n",
    "            current_gen_size = min(gen_batch_size, remaining_samples)\n",
    "            z_generate = torch.randn(current_gen_size, wgan_hyperparams['latent_dim'], device=current_device)\n",
    "            generated_batch_std = generator(z_generate).detach().cpu().numpy()\n",
    "            generated_samples_list.append(generated_batch_std)\n",
    "            remaining_samples -= current_gen_size\n",
    "            \n",
    "    generated_standardized_data_np = np.concatenate(generated_samples_list, axis=0)\n",
    "    generated_data_original_scale_np = generated_standardized_data_np * data_std + data_mean\n",
    "    generated_data_df = pd.DataFrame(generated_data_original_scale_np, columns=all_feature_names)\n",
    "\n",
    "    # if 'CHO' in generated_data_df.columns:\n",
    "    #     cho_column_generated = generated_data_df['CHO'].values\n",
    "    #     processed_cho = np.array([CHO_LEVELS[np.abs(CHO_LEVELS - val).argmin()] for val in cho_column_generated])\n",
    "    #     generated_data_df['CHO'] = processed_cho\n",
    "\n",
    "    for col_name in all_feature_names:\n",
    "        # if col_name == 'CHO': continue # <--- 删除或注释掉这一行，让CHO也参与通用裁剪\n",
    "        original_col_values = input_original_df[col_name]\n",
    "        col_min_original = original_col_values.min()\n",
    "        col_max_original = original_col_values.max()\n",
    "        col_range = col_max_original - col_min_original\n",
    "    \n",
    "        # 这部分原有的1%范围扩展逻辑是好的，保持不变\n",
    "        clip_min_for_col = col_min_original - 0.01 * col_range if col_range != 0 else col_min_original\n",
    "        clip_max_for_col = col_max_original + 0.01 * col_range if col_range != 0 else col_max_original\n",
    "    \n",
    "        # 在这里添加针对 CHO 和 PRO（以及其他您认为需要非负的列）的特殊处理\n",
    "        if col_name in ['CHO', 'PRO']: # 如果有其他列也需要确保非负，可以加入此列表\n",
    "            clip_min_for_col = max(0, clip_min_for_col)\n",
    "    \n",
    "        generated_data_df[col_name] = np.clip(generated_data_df[col_name], clip_min_for_col, clip_max_for_col)\n",
    "    print(f\"{log_prefix} 后处理完成。\")\n",
    "\n",
    "    if output_augmented_data_path:\n",
    "        try:\n",
    "            os.makedirs(os.path.dirname(output_augmented_data_path), exist_ok=True)\n",
    "            generated_data_df.to_excel(output_augmented_data_path, index=False)\n",
    "            print(f\"{log_prefix} 增强数据已保存到: {output_augmented_data_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"{log_prefix} 保存增强数据时发生错误: {e}\")\n",
    "            \n",
    "    return generated_data_df\n",
    "\n",
    "# --- 3. 主流程开始 ---\n",
    "try:\n",
    "    development_df_original = pd.read_excel(DEV_SET_FILE)\n",
    "    final_test_df_original = pd.read_excel(TEST_SET_FILE)\n",
    "    print(f\"开发集形状: {development_df_original.shape}, 最终测试集形状: {final_test_df_original.shape}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"错误: 开发集或测试集文件未找到。请检查路径: {e}\")\n",
    "    exit()\n",
    "\n",
    "X_dev_original = development_df_original.drop(columns=[TARGET_COLUMN])\n",
    "y_dev_original = development_df_original[TARGET_COLUMN]\n",
    "X_final_test = final_test_df_original.drop(columns=[TARGET_COLUMN])\n",
    "y_final_test = final_test_df_original[TARGET_COLUMN]\n",
    "\n",
    "# --- 步骤三：Part 1 - 为SVR确定最佳超参数 ---\n",
    "print(\"\\n--- 步骤三：Part 1 - SVR 超参数调优 ---\")\n",
    "print(\"为超参数调优生成开发集的增强版本...\")\n",
    "num_augmented_samples_for_hpo = len(development_df_original) * 1 # 可以调整增强倍数\n",
    "current_wgan_hpo_params = DEFAULT_WGAN_PARAMS.copy()\n",
    "current_wgan_hpo_params['epochs'] = DEFAULT_WGAN_PARAMS['epochs_for_final'] # 用更长的轮数训练GAN\n",
    "augmented_dev_for_hpo_output_path = os.path.join(AUGMENTED_DATA_OUTPUT_FOLDER, \"augmented_dev_for_svr_hpo.xlsx\")\n",
    "\n",
    "augmented_dev_for_hpo_df = train_and_generate_wgangp(\n",
    "    input_original_df=development_df_original.copy(),\n",
    "    target_col_name=TARGET_COLUMN,\n",
    "    wgan_hyperparams=current_wgan_hpo_params,\n",
    "    num_samples_to_generate=num_augmented_samples_for_hpo,\n",
    "    current_device=device,\n",
    "    fold_num_for_logging=\"HPO_Dev_Set\",\n",
    "    output_augmented_data_path=augmented_dev_for_hpo_output_path\n",
    ")\n",
    "if augmented_dev_for_hpo_df.empty:\n",
    "    print(\"错误：为SVR HPO生成的增强数据为空，无法继续。\")\n",
    "    exit()\n",
    "\n",
    "X_augmented_dev_for_hpo = augmented_dev_for_hpo_df.drop(columns=[TARGET_COLUMN])\n",
    "y_augmented_dev_for_hpo = augmented_dev_for_hpo_df[TARGET_COLUMN]\n",
    "X_combined_dev_for_hpo = pd.concat([X_dev_original, X_augmented_dev_for_hpo], ignore_index=True)\n",
    "y_combined_dev_for_hpo = pd.concat([y_dev_original, y_augmented_dev_for_hpo], ignore_index=True)\n",
    "print(f\"用于SVR HPO的总数据形状: {X_combined_dev_for_hpo.shape}\")\n",
    "\n",
    "# SVR需要Pipeline进行缩放\n",
    "svr_pipeline_for_hpo = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svr', SVR())\n",
    "])\n",
    "\n",
    "random_search_hpo_svr = RandomizedSearchCV(\n",
    "    estimator=svr_pipeline_for_hpo, param_distributions=SVR_PARAM_GRID,\n",
    "    n_iter=N_ITER_RANDOMIZED_SEARCH, cv=N_SPLITS_KFOLD,\n",
    "    scoring='neg_mean_absolute_error', verbose=1, random_state=RANDOM_STATE, n_jobs=-1\n",
    ")\n",
    "print(\"开始SVR超参数搜索 (RandomizedSearchCV)...\")\n",
    "random_search_hpo_svr.fit(X_combined_dev_for_hpo, y_combined_dev_for_hpo)\n",
    "best_overall_svr_pipeline_params = random_search_hpo_svr.best_params_\n",
    "# 提取SVR的最佳参数，去除前缀 'svr__'\n",
    "best_overall_svr_params = {key.split('__')[1]: value for key, value in best_overall_svr_pipeline_params.items() if key.startswith('svr__')}\n",
    "\n",
    "print(f\"找到的最佳SVR Pipeline参数: {best_overall_svr_pipeline_params}\")\n",
    "print(f\"提取的最佳SVR参数: {best_overall_svr_params}\")\n",
    "print(f\"最佳SVR HPO MAE (负值): {random_search_hpo_svr.best_score_}\")\n",
    "\n",
    "# --- 步骤三：Part 2 - K-折交叉验证与动态增强 (SVR) ---\n",
    "print(f\"\\n--- 步骤三：Part 2 - 在开发集上进行 {N_SPLITS_KFOLD}-折交叉验证 (SVR, 动态WGAN-GP增强) ---\")\n",
    "kf = KFold(n_splits=N_SPLITS_KFOLD, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "kfold_cv_val_metrics_list_svr = []\n",
    "kfold_cv_train_metrics_list_svr = []\n",
    "# SVR没有XGBoost那样的evals_result()来画每轮的损失，这里存每折最终的MAE\n",
    "cv_fold_train_maes_svr = []\n",
    "cv_fold_val_maes_svr = []\n",
    "\n",
    "\n",
    "current_wgan_cv_params = DEFAULT_WGAN_PARAMS.copy()\n",
    "current_wgan_cv_params['epochs'] = DEFAULT_WGAN_PARAMS['epochs_for_cv']\n",
    "augmentation_factor_cv = 1 # CV内部的增强倍数\n",
    "\n",
    "for fold_idx, (train_indices, val_indices) in enumerate(kf.split(development_df_original)):\n",
    "    print(f\"\\n--- K-Fold (SVR): 第 {fold_idx + 1}/{N_SPLITS_KFOLD} 折 ---\")\n",
    "    cv_train_original_fold_df = development_df_original.iloc[train_indices]\n",
    "    cv_val_original_fold_df = development_df_original.iloc[val_indices]\n",
    "\n",
    "    X_cv_val_fold = cv_val_original_fold_df.drop(columns=[TARGET_COLUMN])\n",
    "    y_cv_val_fold = cv_val_original_fold_df[TARGET_COLUMN]\n",
    "\n",
    "    print(f\"当前CV训练集（原始）形状: {cv_train_original_fold_df.shape}\")\n",
    "    num_augmented_samples_cv_fold = len(cv_train_original_fold_df) * augmentation_factor_cv\n",
    "    dynamic_wgan_cv_params = current_wgan_cv_params.copy()\n",
    "    dynamic_wgan_cv_params['batch_size'] = min(current_wgan_cv_params['batch_size'], max(1, len(cv_train_original_fold_df) // 2 if len(cv_train_original_fold_df) > 1 else 1) )\n",
    "    \n",
    "    cv_augmented_fold_df = train_and_generate_wgangp(\n",
    "        input_original_df=cv_train_original_fold_df.copy(),\n",
    "        target_col_name=TARGET_COLUMN,\n",
    "        wgan_hyperparams=dynamic_wgan_cv_params,\n",
    "        num_samples_to_generate=num_augmented_samples_cv_fold,\n",
    "        current_device=device,\n",
    "        fold_num_for_logging=(fold_idx + 1),\n",
    "        output_augmented_data_path=None\n",
    "    )\n",
    "    if cv_augmented_fold_df.empty:\n",
    "        print(f\"警告：Fold {fold_idx + 1} 的增强数据为空，跳过此折。\")\n",
    "        cv_fold_train_maes_svr.append(np.nan)\n",
    "        cv_fold_val_maes_svr.append(np.nan)\n",
    "        continue\n",
    "\n",
    "    X_cv_train_original_fold = cv_train_original_fold_df.drop(columns=[TARGET_COLUMN])\n",
    "    y_cv_train_original_fold = cv_train_original_fold_df[TARGET_COLUMN]\n",
    "    X_cv_augmented_fold = cv_augmented_fold_df.drop(columns=[TARGET_COLUMN])\n",
    "    y_cv_augmented_fold = cv_augmented_fold_df[TARGET_COLUMN]\n",
    "\n",
    "    X_cv_train_combined_fold = pd.concat([X_cv_train_original_fold, X_cv_augmented_fold], ignore_index=True)\n",
    "    y_cv_train_combined_fold = pd.concat([y_cv_train_original_fold, y_cv_augmented_fold], ignore_index=True)\n",
    "    print(f\"当前CV训练集（原始+增强后）形状: {X_cv_train_combined_fold.shape}\")\n",
    "\n",
    "    # 在每折内部创建和拟合Pipeline\n",
    "    scaler_fold = StandardScaler()\n",
    "    X_cv_train_combined_fold_scaled = scaler_fold.fit_transform(X_cv_train_combined_fold)\n",
    "    X_cv_val_fold_scaled = scaler_fold.transform(X_cv_val_fold) # 用训练集拟合的scaler转换验证集\n",
    "\n",
    "    model_fold_svr = SVR(**best_overall_svr_params) # 使用HPO找到的最佳SVR参数\n",
    "    \n",
    "    print(f\"Fold {fold_idx + 1} (SVR): 开始训练SVR模型...\")\n",
    "    model_fold_svr.fit(X_cv_train_combined_fold_scaled, y_cv_train_combined_fold)\n",
    "\n",
    "    y_pred_val_fold = model_fold_svr.predict(X_cv_val_fold_scaled)\n",
    "    mae_val = mean_absolute_error(y_cv_val_fold, y_pred_val_fold)\n",
    "    rmse_val = np.sqrt(mean_squared_error(y_cv_val_fold, y_pred_val_fold))\n",
    "    r2_val = r2_score(y_cv_val_fold, y_pred_val_fold)\n",
    "    kfold_cv_val_metrics_list_svr.append({'fold': fold_idx + 1, 'MAE': mae_val, 'RMSE': rmse_val, 'R2': r2_val})\n",
    "    cv_fold_val_maes_svr.append(mae_val)\n",
    "\n",
    "    y_pred_train_fold = model_fold_svr.predict(X_cv_train_combined_fold_scaled)\n",
    "    mae_train = mean_absolute_error(y_cv_train_combined_fold, y_pred_train_fold)\n",
    "    rmse_train = np.sqrt(mean_squared_error(y_cv_train_combined_fold, y_pred_train_fold))\n",
    "    r2_train = r2_score(y_cv_train_combined_fold, y_pred_train_fold)\n",
    "    kfold_cv_train_metrics_list_svr.append({'fold': fold_idx + 1, 'MAE': mae_train, 'RMSE': rmse_train, 'R2': r2_train})\n",
    "    cv_fold_train_maes_svr.append(mae_train)\n",
    "    \n",
    "    print(f\"Fold {fold_idx + 1} (SVR) - CV Train MAE: {mae_train:.4f}, R2: {r2_train:.4f} | CV Val MAE: {mae_val:.4f}, R2: {r2_val:.4f}\")\n",
    "\n",
    "avg_kfold_cv_val_metrics_df_svr = pd.DataFrame(kfold_cv_val_metrics_list_svr)\n",
    "print(\"\\n--- SVR K-折交叉验证平均CV验证性能 (开发集, WGAN-GP动态增强) ---\")\n",
    "if not avg_kfold_cv_val_metrics_df_svr.empty:\n",
    "    avg_mae_cv_val_svr = avg_kfold_cv_val_metrics_df_svr['MAE'].mean()\n",
    "    avg_rmse_cv_val_svr = avg_kfold_cv_val_metrics_df_svr['RMSE'].mean()\n",
    "    avg_r2_cv_val_svr = avg_kfold_cv_val_metrics_df_svr['R2'].mean()\n",
    "    print(f\"平均 CV 验证集 MAE (SVR): {avg_mae_cv_val_svr:.4f}\")\n",
    "    print(f\"平均 CV 验证集 RMSE (SVR): {avg_rmse_cv_val_svr:.4f}\")\n",
    "    print(f\"平均 CV 验证集 R2 (SVR): {avg_r2_cv_val_svr:.4f}\")\n",
    "else:\n",
    "    print(\"SVR K-Fold CV验证结果为空。\")\n",
    "    avg_mae_cv_val_svr, avg_r2_cv_val_svr = np.nan, np.nan\n",
    "\n",
    "avg_kfold_cv_train_metrics_df_svr = pd.DataFrame(kfold_cv_train_metrics_list_svr)\n",
    "print(\"\\n--- SVR K-折交叉验证平均CV训练性能 (开发集, WGAN-GP动态增强) ---\")\n",
    "if not avg_kfold_cv_train_metrics_df_svr.empty:\n",
    "    avg_mae_cv_train_svr = avg_kfold_cv_train_metrics_df_svr['MAE'].mean()\n",
    "    avg_rmse_cv_train_svr = avg_kfold_cv_train_metrics_df_svr['RMSE'].mean() # Added for completeness\n",
    "    avg_r2_cv_train_svr = avg_kfold_cv_train_metrics_df_svr['R2'].mean()\n",
    "    print(f\"平均 CV 训练集 MAE (SVR): {avg_mae_cv_train_svr:.4f}\")\n",
    "    print(f\"平均 CV 训练集 R2 (SVR): {avg_r2_cv_train_svr:.4f}\")\n",
    "else:\n",
    "    print(\"SVR K-Fold CV训练结果为空。\")\n",
    "    avg_mae_cv_train_svr, avg_r2_cv_train_svr = np.nan, np.nan\n",
    "\n",
    "if not np.isnan(avg_mae_cv_val_svr) and not np.isnan(avg_mae_cv_train_svr):\n",
    "    print(\"\\n--- 步骤三 Part 2 结束 (SVR)：生成K-Fold性能图表 ---\")\n",
    "    metrics_plot_names_en = ['MAE', 'R2 Score']\n",
    "    values_cv_val_plot_svr = [avg_mae_cv_val_svr, avg_r2_cv_val_svr]\n",
    "    values_cv_train_plot_svr = [avg_mae_cv_train_svr, avg_r2_cv_train_svr]\n",
    "    x_axis_plot = np.arange(len(metrics_plot_names_en))\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(x_axis_plot - 0.2, values_cv_train_plot_svr, width=0.4, label='CV Train Avg.', align='center', color='skyblue')\n",
    "    plt.bar(x_axis_plot + 0.2, values_cv_val_plot_svr, width=0.4, label='CV Validation Avg.', align='center', color='salmon')\n",
    "    plt.xticks(x_axis_plot, metrics_plot_names_en)\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('SVR: Average K-Fold CV Train vs. CV Validation Metrics (WGAN-GP Augmented)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plot_filename_metrics_svr = os.path.join(OUTPUT_PLOT_PATH, \"svr_kfold_avg_eval_metrics_wgangp.png\")\n",
    "    try:\n",
    "        plt.savefig(plot_filename_metrics_svr, dpi=300, bbox_inches='tight')\n",
    "        print(f\"SVR图表1已保存到: {plot_filename_metrics_svr}\")\n",
    "    except Exception as e:\n",
    "        print(f\"保存SVR图表1时发生错误: {e}\")\n",
    "    plt.show()\n",
    "\n",
    "    # 绘制每折的训练和测试MAE (SVR)\n",
    "    if cv_fold_train_maes_svr and cv_fold_val_maes_svr:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        folds_svr = range(1, len(cv_fold_train_maes_svr) + 1)\n",
    "        plt.plot(folds_svr, cv_fold_train_maes_svr, marker='o', linestyle='-', label='CV Train MAE per Fold', color='dodgerblue')\n",
    "        plt.plot(folds_svr, cv_fold_val_maes_svr, marker='x', linestyle='--', label='CV Validation MAE per Fold', color='orangered')\n",
    "        plt.xlabel('Fold Number')\n",
    "        plt.ylabel('Mean Absolute Error (MAE)')\n",
    "        plt.title('SVR: Training and CV Validation MAE Across Folds (WGAN-GP Augmented)')\n",
    "        plt.xticks(folds_svr)\n",
    "        plt.legend()\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plot_filename_loss_svr = os.path.join(OUTPUT_PLOT_PATH, \"svr_kfold_mae_per_fold_wgangp.png\")\n",
    "        try:\n",
    "            plt.savefig(plot_filename_loss_svr, dpi=300, bbox_inches='tight')\n",
    "            print(f\"SVR图表2已保存到: {plot_filename_loss_svr}\")\n",
    "        except Exception as e:\n",
    "            print(f\"保存SVR图表2时发生错误: {e}\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"没有收集到足够的SVR MAE数据用于绘制图表2。\")\n",
    "else:\n",
    "    print(\"由于SVR K-Fold平均结果为空或NaN，跳过图表绘制。\")\n",
    "\n",
    "\n",
    "# --- 步骤四：训练最终SVR模型 ---\n",
    "print(\"\\n--- 步骤四：训练最终SVR模型 ---\")\n",
    "print(\"为最终SVR模型生成开发集的完整增强版本...\")\n",
    "final_wgan_params_svr = DEFAULT_WGAN_PARAMS.copy()\n",
    "final_wgan_params_svr['epochs'] = DEFAULT_WGAN_PARAMS['epochs_for_final']\n",
    "num_augmented_samples_final_svr = len(development_df_original) * 2 # 最终模型使用更多增强样本\n",
    "final_augmented_dev_output_path_svr = os.path.join(AUGMENTED_DATA_OUTPUT_FOLDER, \"augmented_dev_for_final_svr_model.xlsx\")\n",
    "\n",
    "final_augmented_dev_df_svr = train_and_generate_wgangp(\n",
    "    input_original_df=development_df_original.copy(),\n",
    "    target_col_name=TARGET_COLUMN,\n",
    "    wgan_hyperparams=final_wgan_params_svr,\n",
    "    num_samples_to_generate=num_augmented_samples_final_svr,\n",
    "    current_device=device,\n",
    "    fold_num_for_logging=\"Final_Dev_Set_Aug_SVR\",\n",
    "    output_augmented_data_path=final_augmented_dev_output_path_svr\n",
    ")\n",
    "if final_augmented_dev_df_svr.empty:\n",
    "    print(\"错误：为最终SVR模型生成的增强数据为空，无法继续。\")\n",
    "    exit()\n",
    "\n",
    "X_final_augmented_dev_svr = final_augmented_dev_df_svr.drop(columns=[TARGET_COLUMN])\n",
    "y_final_augmented_dev_svr = final_augmented_dev_df_svr[TARGET_COLUMN]\n",
    "X_train_final_model_svr = pd.concat([X_dev_original, X_final_augmented_dev_svr], ignore_index=True)\n",
    "y_train_final_model_svr = pd.concat([y_dev_original, y_final_augmented_dev_svr], ignore_index=True)\n",
    "print(f\"用于训练最终SVR模型的总数据形状: {X_train_final_model_svr.shape}\")\n",
    "\n",
    "# 创建最终的Pipeline进行训练和保存\n",
    "final_svr_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svr', SVR(**best_overall_svr_params)) # 使用HPO找到的最佳SVR参数\n",
    "])\n",
    "\n",
    "print(\"开始训练最终SVR模型 (Pipeline)...\")\n",
    "final_svr_pipeline.fit(X_train_final_model_svr, y_train_final_model_svr)\n",
    "print(\"最终SVR模型训练完成。\")\n",
    "\n",
    "final_model_path_svr = os.path.join(MODEL_OUTPUT_PATH, \"final_svr_wgangp_pipeline.joblib\")\n",
    "joblib.dump(final_svr_pipeline, final_model_path_svr)\n",
    "print(f\"最终SVR Pipeline已保存到: {final_model_path_svr}\")\n",
    "\n",
    "print(\"\\n--- 步骤四结束 (SVR)：生成最终模型特征重要性图 ---\")\n",
    "# 特征重要性需要从Pipeline中提取SVR模型，并且在缩放后的数据上计算\n",
    "# 或者，如果Pipeline在permutation_importance中被正确处理，可以直接传入Pipeline\n",
    "# 我们将手动缩放数据以确保permutation_importance在正确的数据上运行\n",
    "final_scaler_for_perm = final_svr_pipeline.named_steps['scaler']\n",
    "final_svr_model_for_perm = final_svr_pipeline.named_steps['svr']\n",
    "X_train_final_model_svr_scaled = final_scaler_for_perm.transform(X_train_final_model_svr) # 使用训练好的scaler\n",
    "\n",
    "perm_importance_svr = permutation_importance(\n",
    "    final_svr_model_for_perm, X_train_final_model_svr_scaled, y_train_final_model_svr,\n",
    "    n_repeats=10, random_state=RANDOM_STATE, scoring='neg_mean_absolute_error', n_jobs=-1\n",
    ")\n",
    "sorted_idx_svr = perm_importance_svr.importances_mean.argsort()[::-1]\n",
    "importance_df_svr = pd.DataFrame({\n",
    "    'Feature': X_dev_original.columns[sorted_idx_svr], # 特征名来自原始开发集\n",
    "    'Importance': perm_importance_svr.importances_mean[sorted_idx_svr]\n",
    "})\n",
    "\n",
    "num_features_to_plot = min(20, len(X_dev_original.columns))\n",
    "plot_height = max(6, num_features_to_plot * 0.4)\n",
    "plt.figure(figsize=(10, plot_height))\n",
    "plt.barh(importance_df_svr['Feature'][:num_features_to_plot], importance_df_svr['Importance'][:num_features_to_plot], color='mediumseagreen')\n",
    "plt.xlabel('Permutation Importance (SVR, decrease in MAE)')\n",
    "plt.ylabel('Feature')\n",
    "plt.title(f'SVR: Top {num_features_to_plot} Feature Importances (Final Model with WGAN-GP)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.grid(True, axis='x', linestyle='--', alpha=0.7)\n",
    "plot_filename_importance_svr = os.path.join(OUTPUT_PLOT_PATH, \"final_svr_model_feature_importances_wgangp.png\")\n",
    "try:\n",
    "    plt.savefig(plot_filename_importance_svr, dpi=300, bbox_inches='tight')\n",
    "    print(f\"最终SVR模型特征重要性图已保存到: {plot_filename_importance_svr}\")\n",
    "except Exception as e:\n",
    "    print(f\"保存最终SVR模型特征重要性图时发生错误: {e}\")\n",
    "plt.show()\n",
    "\n",
    "# 如果最佳核是线性的，也可以显示系数\n",
    "if best_overall_svr_params.get('kernel') == 'linear':\n",
    "    try:\n",
    "        linear_coeffs = final_svr_model_for_perm.coef_[0]\n",
    "        # 注意：系数是针对缩放后的数据的，其大小也受缩放影响\n",
    "        # 为了更直观地比较，通常与特征的标准差相乘，但这会复杂化\n",
    "        # 这里我们只展示原始系数的绝对值大小\n",
    "        coeff_df_svr = pd.DataFrame({\n",
    "            'Feature': X_dev_original.columns,\n",
    "            'Absolute Coefficient': np.abs(linear_coeffs)\n",
    "        }).sort_values(by='Absolute Coefficient', ascending=False)\n",
    "\n",
    "        plt.figure(figsize=(10, plot_height))\n",
    "        plt.barh(coeff_df_svr['Feature'][:num_features_to_plot], coeff_df_svr['Absolute Coefficient'][:num_features_to_plot], color='lightcoral')\n",
    "        plt.xlabel('Absolute Coefficient Value (SVR Linear Kernel)')\n",
    "        plt.ylabel('Feature')\n",
    "        plt.title(f'SVR: Top {num_features_to_plot} Abs. Coefficients (Linear Kernel, WGAN-GP)')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.grid(True, axis='x', linestyle='--', alpha=0.7)\n",
    "        plot_filename_coeffs_svr = os.path.join(OUTPUT_PLOT_PATH, \"final_svr_linear_coeffs_wgangp.png\")\n",
    "        plt.savefig(plot_filename_coeffs_svr, dpi=300, bbox_inches='tight')\n",
    "        print(f\"SVR线性核系数图已保存: {plot_filename_coeffs_svr}\")\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"尝试绘制SVR线性核系数时出错: {e}\")\n",
    "\n",
    "\n",
    "# --- 步骤五：最终无偏评估 (在“最终测试集”上使用SVR模型) ---\n",
    "print(\"\\n--- 步骤五：在最终测试集上进行SVR无偏评估 ---\")\n",
    "# final_svr_pipeline_loaded = joblib.load(final_model_path_svr) # 如果分步执行\n",
    "y_pred_final_test_svr = final_svr_pipeline.predict(X_final_test) # Pipeline会自动处理缩放\n",
    "\n",
    "mae_final_svr = mean_absolute_error(y_final_test, y_pred_final_test_svr)\n",
    "rmse_final_svr = np.sqrt(mean_squared_error(y_final_test, y_pred_final_test_svr))\n",
    "r2_final_svr = r2_score(y_final_test, y_pred_final_test_svr)\n",
    "print(\"--- 最终SVR模型在最终测试集上的性能 ---\")\n",
    "print(f\"MAE (SVR): {mae_final_svr:.4f}\")\n",
    "print(f\"RMSE (SVR): {rmse_final_svr:.4f}\")\n",
    "print(f\"R2 Score (SVR): {r2_final_svr:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb11f416-5f8e-42d0-ab83-1b1dadb63b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import joblib\n",
    "print(\"\\n--- 步骤五结束 (SVR)：生成最终测试集真实值 vs 预测值图 ---\")\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(y_final_test, y_pred_final_test_svr, alpha=0.7, edgecolors='w', linewidth=0.5)\n",
    "min_val = min(y_final_test.min(), y_pred_final_test_svr.min())\n",
    "max_val = max(y_final_test.max(), y_pred_final_test_svr.max())\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'k--', lw=2)\n",
    "plt.xlabel('Actual Rowing Distance')\n",
    "plt.ylabel('Predicted Rowing Distance (SVR)')\n",
    "plt.title('SVR Final Model: Actual vs. Predicted (Test Set, WGAN-GP Augmented)')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plot_filename_actual_vs_pred_svr = os.path.join(OUTPUT_PLOT_PATH, \"final_svr_model_actual_vs_predicted_wgangp.png\")\n",
    "try:\n",
    "    plt.savefig(plot_filename_actual_vs_pred_svr, dpi=300, bbox_inches='tight')\n",
    "    print(f\"最终SVR测试集真实值 vs 预测值图已保存到: {plot_filename_actual_vs_pred_svr}\")\n",
    "except Exception as e:\n",
    "    print(f\"保存最终SVR测试集真实值 vs 预测值图时发生错误: {e}\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n--- 整体流程 (SVR + WGAN-GP) 执行完毕 ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fe69ce-a5f8-4e27-82e5-a5280b2b01f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (xgb_gpu_env)",
   "language": "python",
   "name": "xgb_gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
